{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project-Nataly Valenzuela Mullen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import (OrdinalEncoder, MinMaxScaler, StandardScaler, LabelEncoder)\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from scipy.stats import mode\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Change Price?</th>\n",
       "      <th>Buy It Now Price</th>\n",
       "      <th>Image Count</th>\n",
       "      <th>Hood</th>\n",
       "      <th>Lights</th>\n",
       "      <th>AMZSize</th>\n",
       "      <th>Sold Quantity</th>\n",
       "      <th>Category_Alcohol</th>\n",
       "      <th>Category_Comedy</th>\n",
       "      <th>Category_Costume</th>\n",
       "      <th>...</th>\n",
       "      <th>Color_blue</th>\n",
       "      <th>Color_green</th>\n",
       "      <th>Color_grey</th>\n",
       "      <th>Color_multicolor</th>\n",
       "      <th>Color_orange</th>\n",
       "      <th>Color_purple</th>\n",
       "      <th>Color_red</th>\n",
       "      <th>Color_turquoise</th>\n",
       "      <th>Color_white</th>\n",
       "      <th>Color_yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Change Price?  Buy It Now Price  Image Count  Hood  Lights  AMZSize  \\\n",
       "0              0          0.428571            6     0       0      5.0   \n",
       "1              1          0.714286            6     0       0      3.0   \n",
       "\n",
       "   Sold Quantity  Category_Alcohol  Category_Comedy  Category_Costume  ...  \\\n",
       "0             10                 0                0                 0  ...   \n",
       "1             44                 0                0                 0  ...   \n",
       "\n",
       "   Color_blue  Color_green  Color_grey  Color_multicolor  Color_orange  \\\n",
       "0           0            0           0                 0             0   \n",
       "1           0            0           0                 0             0   \n",
       "\n",
       "   Color_purple  Color_red  Color_turquoise  Color_white  Color_yellow  \n",
       "0             0          0                0            0             0  \n",
       "1             0          0                0            0             0  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data\n",
    "scaled_df= pd.read_csv(\"scaled_df.csv\")\n",
    "scaled_df.drop([\"Classification\"],axis = 1, inplace=True)\n",
    "categoricalCol=['Category', 'Character', 'Color']\n",
    "scaled_df= pd.get_dummies(scaled_df, columns=categoricalCol, drop_first=True)\n",
    "scaled_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=scaled_df.drop(['Sold Quantity'],axis = 1)\n",
    "y=scaled_df['Sold Quantity']\n",
    "labels=[f'cat {i}' for i in range(len(np.arange(0,y.max()+10,5)) -1)]\n",
    "yCat=pd.cut(y, bins=np.arange(0,y.max()+10,5), labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "features_list = X.columns.values\n",
    "feature_importance = clf.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "\n",
    "plt.figure(figsize=(5,15))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature importances Class')\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Change Price?', 'Buy It Now Price', 'Image Count', 'Hood', 'Lights',\n",
       "       'AMZSize', 'Category_Alcohol', 'Category_Comedy', 'Category_Costume',\n",
       "       'Category_Cute', 'Category_Naughty', 'Category_Pop culture',\n",
       "       'Category_Religious', 'Character_Dinosaur', 'Character_Dog',\n",
       "       'Character_Elf', 'Character_Fireplace', 'Character_Gingerbread man',\n",
       "       'Character_Giraffe', 'Character_Godzilla', 'Character_Internet',\n",
       "       'Character_Jesus', 'Character_Llama', 'Character_Menorah',\n",
       "       'Character_Mrs. Claus', 'Character_Penguins', 'Character_Polar bear',\n",
       "       'Character_Reindeer', 'Character_Santa', 'Character_Skull',\n",
       "       'Character_Sleigh', 'Character_Snowman', 'Character_Tree',\n",
       "       'Character_Tuxedo', 'Character_Tv Show', 'Character_Wine',\n",
       "       'Character_Yeti', 'Color_blue', 'Color_green', 'Color_grey',\n",
       "       'Color_multicolor', 'Color_orange', 'Color_purple', 'Color_red',\n",
       "       'Color_turquoise', 'Color_white', 'Color_yellow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[['AMZSize','Image Count', 'Buy It Now Price', 'Change Price?','Category_Pop culture', \n",
    "     'Color_blue','Category_Comedy', 'Lights', 'Character_Elf', 'Character_Dog',\n",
    "      'Character_Reindeer','Color_grey','Character_Santa','Hood']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # X.drop(X.iloc[:, 5:14], inplace = True, axis = 1) #category\n",
    "# X.drop(X.iloc[:, 5:10], inplace = True, axis = 1) #category but not dropping pop culture\n",
    "# X.drop(X.iloc[:, 6:21], inplace = True, axis = 1) #category-subcat but not dropping reindeer or santa\n",
    "# X.drop(X.iloc[:, 8:16], inplace = True, axis = 1) #color not dropping blue\n",
    "# X.drop(X.iloc[:, 9:14], inplace = True, axis = 1) #color not dropping red\n",
    "# X.drop(X.iloc[:, 10:13], inplace = True, axis = 1) #color\n",
    "\n",
    "# X.drop(X.iloc[:, 43:46], inplace = True, axis = 1) #color\n",
    "# # X.drop(X.iloc[:, 24:26], inplace = True, axis = 1) #classification\n",
    "# # # X.drop(X.iloc[:, 14:38], inplace = True, axis = 1) #character\n",
    "# # X.drop(X.iloc[:, 4:5], inplace = True, axis = 1) #size\n",
    "# X.drop(X.iloc[:, 36:46], inplace = True, axis = 1) #color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMZSize</th>\n",
       "      <th>Image Count</th>\n",
       "      <th>Buy It Now Price</th>\n",
       "      <th>Change Price?</th>\n",
       "      <th>Category_Pop culture</th>\n",
       "      <th>Color_blue</th>\n",
       "      <th>Category_Comedy</th>\n",
       "      <th>Lights</th>\n",
       "      <th>Character_Elf</th>\n",
       "      <th>Character_Dog</th>\n",
       "      <th>Character_Reindeer</th>\n",
       "      <th>Color_grey</th>\n",
       "      <th>Character_Santa</th>\n",
       "      <th>Hood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMZSize  Image Count  Buy It Now Price  Change Price?  \\\n",
       "0      5.0            6          0.428571              0   \n",
       "\n",
       "   Category_Pop culture  Color_blue  Category_Comedy  Lights  Character_Elf  \\\n",
       "0                     0           0                0       0              0   \n",
       "\n",
       "   Character_Dog  Character_Reindeer  Color_grey  Character_Santa  Hood  \n",
       "0              0                   1           0                0     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (301, 14)\n",
      "X_test shape:  (129, 14)\n",
      "y_train shape:  (301,)\n",
      "y_test shape:  (129,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values, test_size=0.30, random_state=42)\n",
    "\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"y_test shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (301, 14)\n",
      "X_test shape:  (129, 14)\n",
      "y_train shape:  (301,)\n",
      "y_test shape:  (129,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, yCat_train, yCat_test = train_test_split(X, yCat.values, test_size=0.30, random_state=42)\n",
    "\n",
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_train shape: \",y_train.shape)\n",
    "print(\"y_test shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Sold Quantity   R-squared:                       0.288\n",
      "Model:                            OLS   Adj. R-squared:                  0.264\n",
      "Method:                 Least Squares   F-statistic:                     11.96\n",
      "Date:                Fri, 19 Nov 2021   Prob (F-statistic):           2.08e-23\n",
      "Time:                        19:38:27   Log-Likelihood:                -2117.9\n",
      "No. Observations:                 430   AIC:                             4266.\n",
      "Df Residuals:                     415   BIC:                             4327.\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "AMZSize                 -0.3663      0.788     -0.465      0.642      -1.916       1.183\n",
      "Image Count             -1.8171      1.352     -1.344      0.180      -4.475       0.840\n",
      "Buy It Now Price        80.0147      9.228      8.670      0.000      61.874      98.155\n",
      "Change Price?           20.2854      4.050      5.008      0.000      12.324      28.247\n",
      "Category_Pop culture     6.7092      3.871      1.733      0.084      -0.900      14.318\n",
      "Color_blue             -14.0397      5.462     -2.570      0.011     -24.777      -3.302\n",
      "Category_Comedy         -4.3472      5.167     -0.841      0.401     -14.505       5.810\n",
      "Lights                  11.9919      4.253      2.820      0.005       3.632      20.352\n",
      "Character_Elf            6.4951      6.201      1.047      0.296      -5.695      18.685\n",
      "Character_Dog            0.4189      6.969      0.060      0.952     -13.280      14.118\n",
      "Character_Reindeer      14.4358      5.257      2.746      0.006       4.102      24.770\n",
      "Color_grey             -25.8796      7.650     -3.383      0.001     -40.917     -10.842\n",
      "Character_Santa          6.4243      4.398      1.461      0.145      -2.221      15.069\n",
      "Hood                     1.4041      9.756      0.144      0.886     -17.773      20.581\n",
      "const                  -24.5285      7.582     -3.235      0.001     -39.432      -9.625\n",
      "==============================================================================\n",
      "Omnibus:                      137.706   Durbin-Watson:                   1.352\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              360.900\n",
      "Skew:                           1.572   Prob(JB):                     4.28e-79\n",
      "Kurtosis:                       6.204   Cond. No.                         47.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "feature_matrix = sm.add_constant(X, prepend=False)\n",
    "#Fit and summarize OLS model\n",
    "model = sm.OLS(y, feature_matrix)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2855092164554113\n",
      "0.21684658145525337\n",
      "Training RMSE:  30.614316048256367\n",
      "Test RMSE:  40.41340524577581\n"
     ]
    }
   ],
   "source": [
    "lr=LinearRegression()\n",
    "lr=lr.fit(X_train, y_train)\n",
    "y_train_pred=lr.predict(X_train)\n",
    "y_test_pred=lr.predict(X_test)\n",
    "\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20992343173296502\n",
      "0.144437392062702\n",
      "Training RMSE:  32.192954572668576\n",
      "Test RMSE:  42.24039002420508\n"
     ]
    }
   ],
   "source": [
    "lasso= Lasso()\n",
    "lasso=lasso.fit(X_train, y_train)\n",
    "y_train_pred=lasso.predict(X_train)\n",
    "y_test_pred=lasso.predict(X_test)\n",
    "print(lasso.score(X_train, y_train))\n",
    "print(lasso.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': 1000,\n",
       " 'normalize': False,\n",
       " 'positive': False,\n",
       " 'precompute': False,\n",
       " 'random_state': None,\n",
       " 'selection': 'cyclic',\n",
       " 'tol': 0.0001,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.099, 'random_state': 42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.210295969602524"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDepth=clf.tree_.max_depth\n",
    "param_grid = {'alpha': np.arange(0,0.1,0.001),\n",
    "             'random_state':[42]}\n",
    "lasso= Lasso()\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.099</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.099, 'random_state': 42}</td>\n",
       "      <td>0.194880</td>\n",
       "      <td>0.227773</td>\n",
       "      <td>0.211807</td>\n",
       "      <td>0.175531</td>\n",
       "      <td>0.241488</td>\n",
       "      <td>0.210296</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.098</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.098, 'random_state': 42}</td>\n",
       "      <td>0.194795</td>\n",
       "      <td>0.227879</td>\n",
       "      <td>0.211796</td>\n",
       "      <td>0.175516</td>\n",
       "      <td>0.241439</td>\n",
       "      <td>0.210285</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.097</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.097, 'random_state': 42}</td>\n",
       "      <td>0.194709</td>\n",
       "      <td>0.227986</td>\n",
       "      <td>0.211784</td>\n",
       "      <td>0.175502</td>\n",
       "      <td>0.241388</td>\n",
       "      <td>0.210274</td>\n",
       "      <td>0.023390</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.096</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.096, 'random_state': 42}</td>\n",
       "      <td>0.194623</td>\n",
       "      <td>0.228096</td>\n",
       "      <td>0.211772</td>\n",
       "      <td>0.175487</td>\n",
       "      <td>0.241338</td>\n",
       "      <td>0.210263</td>\n",
       "      <td>0.023409</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.095</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.095, 'random_state': 42}</td>\n",
       "      <td>0.194537</td>\n",
       "      <td>0.228202</td>\n",
       "      <td>0.211759</td>\n",
       "      <td>0.175472</td>\n",
       "      <td>0.241287</td>\n",
       "      <td>0.210251</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.094</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.094, 'random_state': 42}</td>\n",
       "      <td>0.194450</td>\n",
       "      <td>0.228308</td>\n",
       "      <td>0.211746</td>\n",
       "      <td>0.175457</td>\n",
       "      <td>0.241235</td>\n",
       "      <td>0.210239</td>\n",
       "      <td>0.023446</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.093</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.093, 'random_state': 42}</td>\n",
       "      <td>0.194363</td>\n",
       "      <td>0.228429</td>\n",
       "      <td>0.211732</td>\n",
       "      <td>0.175441</td>\n",
       "      <td>0.241183</td>\n",
       "      <td>0.210230</td>\n",
       "      <td>0.023468</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.092</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.092, 'random_state': 42}</td>\n",
       "      <td>0.194275</td>\n",
       "      <td>0.228576</td>\n",
       "      <td>0.211718</td>\n",
       "      <td>0.175425</td>\n",
       "      <td>0.241131</td>\n",
       "      <td>0.210225</td>\n",
       "      <td>0.023493</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.091</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.091, 'random_state': 42}</td>\n",
       "      <td>0.194188</td>\n",
       "      <td>0.228723</td>\n",
       "      <td>0.211703</td>\n",
       "      <td>0.175408</td>\n",
       "      <td>0.241078</td>\n",
       "      <td>0.210220</td>\n",
       "      <td>0.023519</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.09</td>\n",
       "      <td>42</td>\n",
       "      <td>{'alpha': 0.09, 'random_state': 42}</td>\n",
       "      <td>0.194099</td>\n",
       "      <td>0.228869</td>\n",
       "      <td>0.211687</td>\n",
       "      <td>0.175392</td>\n",
       "      <td>0.241025</td>\n",
       "      <td>0.210215</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "99       0.004800      0.000746         0.002201        0.000400       0.099   \n",
       "98       0.003801      0.000400         0.002600        0.000489       0.098   \n",
       "97       0.004803      0.001163         0.002400        0.000485       0.097   \n",
       "96       0.004802      0.000980         0.003199        0.000398       0.096   \n",
       "95       0.004400      0.000489         0.002401        0.000490       0.095   \n",
       "94       0.003600      0.000490         0.002400        0.000490       0.094   \n",
       "93       0.004401      0.000801         0.003200        0.000748       0.093   \n",
       "92       0.003999      0.000002         0.002401        0.000490       0.092   \n",
       "91       0.004582      0.000814         0.002801        0.000750       0.091   \n",
       "90       0.003400      0.000490         0.002400        0.000490        0.09   \n",
       "\n",
       "   param_random_state                                params  \\\n",
       "99                 42  {'alpha': 0.099, 'random_state': 42}   \n",
       "98                 42  {'alpha': 0.098, 'random_state': 42}   \n",
       "97                 42  {'alpha': 0.097, 'random_state': 42}   \n",
       "96                 42  {'alpha': 0.096, 'random_state': 42}   \n",
       "95                 42  {'alpha': 0.095, 'random_state': 42}   \n",
       "94                 42  {'alpha': 0.094, 'random_state': 42}   \n",
       "93                 42  {'alpha': 0.093, 'random_state': 42}   \n",
       "92                 42  {'alpha': 0.092, 'random_state': 42}   \n",
       "91                 42  {'alpha': 0.091, 'random_state': 42}   \n",
       "90                 42   {'alpha': 0.09, 'random_state': 42}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "99           0.194880           0.227773           0.211807   \n",
       "98           0.194795           0.227879           0.211796   \n",
       "97           0.194709           0.227986           0.211784   \n",
       "96           0.194623           0.228096           0.211772   \n",
       "95           0.194537           0.228202           0.211759   \n",
       "94           0.194450           0.228308           0.211746   \n",
       "93           0.194363           0.228429           0.211732   \n",
       "92           0.194275           0.228576           0.211718   \n",
       "91           0.194188           0.228723           0.211703   \n",
       "90           0.194099           0.228869           0.211687   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "99           0.175531           0.241488         0.210296        0.023354   \n",
       "98           0.175516           0.241439         0.210285        0.023372   \n",
       "97           0.175502           0.241388         0.210274        0.023390   \n",
       "96           0.175487           0.241338         0.210263        0.023409   \n",
       "95           0.175472           0.241287         0.210251        0.023428   \n",
       "94           0.175457           0.241235         0.210239        0.023446   \n",
       "93           0.175441           0.241183         0.210230        0.023468   \n",
       "92           0.175425           0.241131         0.210225        0.023493   \n",
       "91           0.175408           0.241078         0.210220        0.023519   \n",
       "90           0.175392           0.241025         0.210215        0.023545   \n",
       "\n",
       "    rank_test_score  \n",
       "99                1  \n",
       "98                2  \n",
       "97                3  \n",
       "96                4  \n",
       "95                5  \n",
       "94                6  \n",
       "93                7  \n",
       "92                8  \n",
       "91                9  \n",
       "90               10  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2855092164554113\n",
      "0.21684658145525337\n",
      "Training RMSE:  30.614316048256367\n",
      "Test RMSE:  40.41340524577581\n"
     ]
    }
   ],
   "source": [
    "lasso= Lasso(alpha=0)\n",
    "lasso=lasso.fit(X_train, y_train)\n",
    "y_train_pred=lasso.predict(X_train)\n",
    "y_test_pred=lasso.predict(X_test)\n",
    "print(lasso.score(X_train, y_train))\n",
    "print(lasso.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2839507098864915\n",
      "0.21684725410543482\n",
      "Training RMSE:  30.647687103155658\n",
      "Test RMSE:  40.413387890242674\n"
     ]
    }
   ],
   "source": [
    "lasso= Lasso(alpha=0.099)\n",
    "lasso=lasso.fit(X_train, y_train)\n",
    "y_train_pred=lasso.predict(X_train)\n",
    "y_test_pred=lasso.predict(X_test)\n",
    "print(lasso.score(X_train, y_train))\n",
    "print(lasso.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model is not a good fit for this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988338256360634\n",
      "-0.042761938760697005\n",
      "Training RMSE:  3.9111816875071184\n",
      "Test RMSE:  46.633134408982215\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf=tree.DecisionTreeRegressor(random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 42,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 16, 'max_features': 0.6, 'max_leaf_nodes': 20, 'min_samples_leaf': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41483769073224136"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDepth=clf.tree_.max_depth\n",
    "param_grid = {'max_depth':range(1, maxDepth+1),\n",
    "              'max_features':[0.2,0.4,0.6,0.8], \n",
    "              'max_leaf_nodes':[20,30,40,50],\n",
    "             'min_samples_leaf': [1,2,5,10]}\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.706415e-04</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>4.711456e-04</td>\n",
       "      <td>16</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 16, 'max_features': 0.6, 'max_le...</td>\n",
       "      <td>0.476004</td>\n",
       "      <td>0.477037</td>\n",
       "      <td>0.291472</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.087233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>0.002999</td>\n",
       "      <td>1.655632e-06</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>4.739557e-04</td>\n",
       "      <td>19</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 19, 'max_features': 0.6, 'max_le...</td>\n",
       "      <td>0.341236</td>\n",
       "      <td>0.365355</td>\n",
       "      <td>0.374348</td>\n",
       "      <td>0.360313</td>\n",
       "      <td>0.013980</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0.003668</td>\n",
       "      <td>4.709240e-04</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>4.720467e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 13, 'max_features': 0.4, 'max_le...</td>\n",
       "      <td>0.397027</td>\n",
       "      <td>0.308825</td>\n",
       "      <td>0.363806</td>\n",
       "      <td>0.356553</td>\n",
       "      <td>0.036372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.002666</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>5.619580e-07</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.389755</td>\n",
       "      <td>0.332317</td>\n",
       "      <td>0.282516</td>\n",
       "      <td>0.334863</td>\n",
       "      <td>0.043817</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>8.171187e-04</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>4.702466e-04</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 16, 'max_features': 0.4, 'max_le...</td>\n",
       "      <td>0.292185</td>\n",
       "      <td>0.551362</td>\n",
       "      <td>0.145131</td>\n",
       "      <td>0.329559</td>\n",
       "      <td>0.167935</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>0.003001</td>\n",
       "      <td>4.495664e-07</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>9.440894e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 0.6, 'max_le...</td>\n",
       "      <td>0.279964</td>\n",
       "      <td>0.322502</td>\n",
       "      <td>0.380587</td>\n",
       "      <td>0.327684</td>\n",
       "      <td>0.041242</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.713723e-04</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>4.732812e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 0.4, 'max_le...</td>\n",
       "      <td>0.350268</td>\n",
       "      <td>0.407696</td>\n",
       "      <td>0.221107</td>\n",
       "      <td>0.326357</td>\n",
       "      <td>0.078029</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>0.004333</td>\n",
       "      <td>9.448200e-04</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.700783e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 13, 'max_features': 0.4, 'max_le...</td>\n",
       "      <td>0.326138</td>\n",
       "      <td>0.256333</td>\n",
       "      <td>0.392644</td>\n",
       "      <td>0.325038</td>\n",
       "      <td>0.055654</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.717637e-04</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>4.721571e-04</td>\n",
       "      <td>17</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 17, 'max_features': 0.8, 'max_le...</td>\n",
       "      <td>0.445535</td>\n",
       "      <td>0.180842</td>\n",
       "      <td>0.346567</td>\n",
       "      <td>0.324315</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.005332</td>\n",
       "      <td>4.726107e-04</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>8.778064e-07</td>\n",
       "      <td>12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 12, 'max_features': 0.8, 'max_le...</td>\n",
       "      <td>0.405401</td>\n",
       "      <td>0.379508</td>\n",
       "      <td>0.187155</td>\n",
       "      <td>0.324021</td>\n",
       "      <td>0.097355</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "992        0.003334  4.706415e-04         0.002333    4.711456e-04   \n",
       "1189       0.002999  1.655632e-06         0.002332    4.739557e-04   \n",
       "792        0.003668  4.709240e-04         0.002332    4.720467e-04   \n",
       "549        0.002666  4.714266e-04         0.002000    5.619580e-07   \n",
       "976        0.003000  8.171187e-04         0.002668    4.702466e-04   \n",
       "1248       0.003001  4.495664e-07         0.002667    9.440894e-04   \n",
       "1238       0.002667  4.713723e-04         0.002333    4.732812e-04   \n",
       "784        0.004333  9.448200e-04         0.003334    4.700783e-04   \n",
       "1077       0.003334  4.717637e-04         0.002333    4.721571e-04   \n",
       "765        0.005332  4.726107e-04         0.002999    8.778064e-07   \n",
       "\n",
       "     param_max_depth param_max_features param_max_leaf_nodes  \\\n",
       "992               16                0.6                   20   \n",
       "1189              19                0.6                   30   \n",
       "792               13                0.4                   40   \n",
       "549                9                0.6                   30   \n",
       "976               16                0.4                   20   \n",
       "1248              20                0.6                   20   \n",
       "1238              20                0.4                   30   \n",
       "784               13                0.4                   20   \n",
       "1077              17                0.8                   30   \n",
       "765               12                0.8                   50   \n",
       "\n",
       "     param_min_samples_leaf  \\\n",
       "992                       1   \n",
       "1189                      2   \n",
       "792                       1   \n",
       "549                       2   \n",
       "976                       1   \n",
       "1248                      1   \n",
       "1238                      5   \n",
       "784                       1   \n",
       "1077                      2   \n",
       "765                       2   \n",
       "\n",
       "                                                 params  split0_test_score  \\\n",
       "992   {'max_depth': 16, 'max_features': 0.6, 'max_le...           0.476004   \n",
       "1189  {'max_depth': 19, 'max_features': 0.6, 'max_le...           0.341236   \n",
       "792   {'max_depth': 13, 'max_features': 0.4, 'max_le...           0.397027   \n",
       "549   {'max_depth': 9, 'max_features': 0.6, 'max_lea...           0.389755   \n",
       "976   {'max_depth': 16, 'max_features': 0.4, 'max_le...           0.292185   \n",
       "1248  {'max_depth': 20, 'max_features': 0.6, 'max_le...           0.279964   \n",
       "1238  {'max_depth': 20, 'max_features': 0.4, 'max_le...           0.350268   \n",
       "784   {'max_depth': 13, 'max_features': 0.4, 'max_le...           0.326138   \n",
       "1077  {'max_depth': 17, 'max_features': 0.8, 'max_le...           0.445535   \n",
       "765   {'max_depth': 12, 'max_features': 0.8, 'max_le...           0.405401   \n",
       "\n",
       "      split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "992            0.477037           0.291472         0.414838        0.087233   \n",
       "1189           0.365355           0.374348         0.360313        0.013980   \n",
       "792            0.308825           0.363806         0.356553        0.036372   \n",
       "549            0.332317           0.282516         0.334863        0.043817   \n",
       "976            0.551362           0.145131         0.329559        0.167935   \n",
       "1248           0.322502           0.380587         0.327684        0.041242   \n",
       "1238           0.407696           0.221107         0.326357        0.078029   \n",
       "784            0.256333           0.392644         0.325038        0.055654   \n",
       "1077           0.180842           0.346567         0.324315        0.109200   \n",
       "765            0.379508           0.187155         0.324021        0.097355   \n",
       "\n",
       "      rank_test_score  \n",
       "992                 1  \n",
       "1189                2  \n",
       "792                 3  \n",
       "549                 4  \n",
       "976                 5  \n",
       "1248                6  \n",
       "1238                7  \n",
       "784                 8  \n",
       "1077                9  \n",
       "765                10  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3369948270796902\n",
      "0.23617124313965165\n",
      "Training RMSE:  29.490674402872564\n",
      "Test RMSE:  39.91168140256353\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeRegressor(max_depth=4, max_features= 0.4, random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4975822711038823\n",
      "0.30047392294196773\n",
      "Training RMSE:  25.671942055023905\n",
      "Test RMSE:  38.19477677461694\n"
     ]
    }
   ],
   "source": [
    "#BEST\n",
    "clf=tree.DecisionTreeRegressor(max_depth=6, max_features= 0.4, random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4725312455520928\n",
      "0.19880998114977988\n",
      "Training RMSE:  26.304170752839614\n",
      "Test RMSE:  40.87613143114981\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeRegressor(max_depth=5, max_features= 0.8, random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6655770287478826\n",
      "0.22437423120476285\n",
      "Training RMSE:  20.944707341799354\n",
      "Test RMSE:  40.2187099785595\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeRegressor(max_depth=7, max_features= 0.6, random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf=tree.DecisionTreeRegressor(max_depth=4, max_features= 0.4, random_state=42, max_leaf_nodes= 30, min_samples_leaf= 1)\n",
    "# clf=clf.fit(X_train, y_train)\n",
    "# y_train_pred=clf.predict(X_train)\n",
    "# y_test_pred=clf.predict(X_test)\n",
    "# print(clf.score(X_train, y_train))\n",
    "# print(clf.score(X_test, y_test))\n",
    "\n",
    "# print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "# print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'max_features': 0.2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34006579818474103"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDepth=clf.tree_.max_depth\n",
    "param_grid = {'max_depth':range(1, maxDepth+1),\n",
    "              'max_features':[0.2,0.4,0.6,0.8]}\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>3.996137e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.2}</td>\n",
       "      <td>0.347989</td>\n",
       "      <td>0.211867</td>\n",
       "      <td>0.434222</td>\n",
       "      <td>0.360752</td>\n",
       "      <td>0.345500</td>\n",
       "      <td>0.340066</td>\n",
       "      <td>0.071862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>1.165822e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.6}</td>\n",
       "      <td>0.463087</td>\n",
       "      <td>0.258284</td>\n",
       "      <td>0.555592</td>\n",
       "      <td>0.270407</td>\n",
       "      <td>0.117326</td>\n",
       "      <td>0.332939</td>\n",
       "      <td>0.156516</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>8.006472e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.2}</td>\n",
       "      <td>0.310638</td>\n",
       "      <td>0.228321</td>\n",
       "      <td>0.340055</td>\n",
       "      <td>0.320309</td>\n",
       "      <td>0.205227</td>\n",
       "      <td>0.280910</td>\n",
       "      <td>0.053717</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>6.975526e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.6}</td>\n",
       "      <td>0.311977</td>\n",
       "      <td>0.225664</td>\n",
       "      <td>0.208643</td>\n",
       "      <td>0.360957</td>\n",
       "      <td>0.213513</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.061295</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>9.802118e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.8}</td>\n",
       "      <td>0.426099</td>\n",
       "      <td>0.061155</td>\n",
       "      <td>0.286070</td>\n",
       "      <td>0.302562</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.239068</td>\n",
       "      <td>0.132047</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>9.789871e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.4}</td>\n",
       "      <td>0.265510</td>\n",
       "      <td>0.253221</td>\n",
       "      <td>0.331533</td>\n",
       "      <td>0.200917</td>\n",
       "      <td>0.097848</td>\n",
       "      <td>0.229806</td>\n",
       "      <td>0.077999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>4.898826e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.6}</td>\n",
       "      <td>0.353987</td>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.496411</td>\n",
       "      <td>0.126090</td>\n",
       "      <td>0.112985</td>\n",
       "      <td>0.223290</td>\n",
       "      <td>0.174259</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>4.004723e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.6}</td>\n",
       "      <td>0.312929</td>\n",
       "      <td>0.196294</td>\n",
       "      <td>0.238581</td>\n",
       "      <td>0.142216</td>\n",
       "      <td>0.218783</td>\n",
       "      <td>0.221761</td>\n",
       "      <td>0.055820</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>7.490294e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.6}</td>\n",
       "      <td>0.222927</td>\n",
       "      <td>0.391421</td>\n",
       "      <td>0.195432</td>\n",
       "      <td>0.116089</td>\n",
       "      <td>0.133050</td>\n",
       "      <td>0.211784</td>\n",
       "      <td>0.097998</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>3.992340e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.8}</td>\n",
       "      <td>0.301533</td>\n",
       "      <td>0.176460</td>\n",
       "      <td>0.257304</td>\n",
       "      <td>0.158035</td>\n",
       "      <td>0.067786</td>\n",
       "      <td>0.192224</td>\n",
       "      <td>0.081346</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "24       0.003801      0.000749         0.002799    3.996137e-04   \n",
       "26       0.003400      0.001357         0.002801    1.165822e-03   \n",
       "16       0.004201      0.000749         0.002600    8.006472e-04   \n",
       "14       0.002998      0.000002         0.002000    6.975526e-07   \n",
       "27       0.003600      0.000800         0.003201    9.802118e-04   \n",
       "21       0.003800      0.000400         0.003201    9.789871e-04   \n",
       "22       0.004802      0.000400         0.002599    4.898826e-04   \n",
       "10       0.002999      0.000002         0.002201    4.004723e-04   \n",
       "18       0.003600      0.000801         0.002800    7.490294e-04   \n",
       "15       0.003201      0.000402         0.003200    3.992340e-04   \n",
       "\n",
       "   param_max_depth param_max_features                                 params  \\\n",
       "24               7                0.2  {'max_depth': 7, 'max_features': 0.2}   \n",
       "26               7                0.6  {'max_depth': 7, 'max_features': 0.6}   \n",
       "16               5                0.2  {'max_depth': 5, 'max_features': 0.2}   \n",
       "14               4                0.6  {'max_depth': 4, 'max_features': 0.6}   \n",
       "27               7                0.8  {'max_depth': 7, 'max_features': 0.8}   \n",
       "21               6                0.4  {'max_depth': 6, 'max_features': 0.4}   \n",
       "22               6                0.6  {'max_depth': 6, 'max_features': 0.6}   \n",
       "10               3                0.6  {'max_depth': 3, 'max_features': 0.6}   \n",
       "18               5                0.6  {'max_depth': 5, 'max_features': 0.6}   \n",
       "15               4                0.8  {'max_depth': 4, 'max_features': 0.8}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "24           0.347989           0.211867           0.434222   \n",
       "26           0.463087           0.258284           0.555592   \n",
       "16           0.310638           0.228321           0.340055   \n",
       "14           0.311977           0.225664           0.208643   \n",
       "27           0.426099           0.061155           0.286070   \n",
       "21           0.265510           0.253221           0.331533   \n",
       "22           0.353987           0.026977           0.496411   \n",
       "10           0.312929           0.196294           0.238581   \n",
       "18           0.222927           0.391421           0.195432   \n",
       "15           0.301533           0.176460           0.257304   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "24           0.360752           0.345500         0.340066        0.071862   \n",
       "26           0.270407           0.117326         0.332939        0.156516   \n",
       "16           0.320309           0.205227         0.280910        0.053717   \n",
       "14           0.360957           0.213513         0.264151        0.061295   \n",
       "27           0.302562           0.119452         0.239068        0.132047   \n",
       "21           0.200917           0.097848         0.229806        0.077999   \n",
       "22           0.126090           0.112985         0.223290        0.174259   \n",
       "10           0.142216           0.218783         0.221761        0.055820   \n",
       "18           0.116089           0.133050         0.211784        0.097998   \n",
       "15           0.158035           0.067786         0.192224        0.081346   \n",
       "\n",
       "    rank_test_score  \n",
       "24                1  \n",
       "26                2  \n",
       "16                3  \n",
       "14                4  \n",
       "27                5  \n",
       "21                6  \n",
       "22                7  \n",
       "10                8  \n",
       "18                9  \n",
       "15               10  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796303437501731\n",
      "-0.028400212731035435\n",
      "Training RMSE:  20.49990901094639\n",
      "Test RMSE:  46.31088715790144\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeRegressor(max_depth=7, max_features= 0.8, random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31002359681237524\n",
      "0.17664998042098567\n",
      "Training RMSE:  30.08453927881351\n",
      "Test RMSE:  41.43756927946151\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeRegressor(max_depth=3, max_features= 0.6, random_state=42)\n",
    "clf=clf.fit(X_train, y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9667774086378738\n",
      "0.17829457364341086\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(random_state=42)\n",
    "clf=clf.fit(X_train, yCat_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, yCat_train))\n",
    "print(clf.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 42,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'max_features': 0.6, 'max_leaf_nodes': 20, 'min_samples_leaf': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31240437158469947"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxDepth=clf.tree_.max_depth\n",
    "param_grid = {'max_depth':range(1, maxDepth+1),\n",
    "              'max_features':[0.2,0.4,0.6,0.8], \n",
    "              'max_leaf_nodes':[20,30,40,50],\n",
    "             'min_samples_leaf': [1,2,5,10]}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, yCat_train)\n",
    "print(grid_search.best_params_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.004002</td>\n",
       "      <td>8.983134e-04</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>4.015974e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.312404</td>\n",
       "      <td>0.018051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.003202</td>\n",
       "      <td>7.492865e-04</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>3.992348e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 11, 'max_features': 0.4, 'max_le...</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.305738</td>\n",
       "      <td>0.038037</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>7.835234e-07</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.072619e-06</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 13, 'max_features': 0.2, 'max_le...</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.302295</td>\n",
       "      <td>0.028264</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.002800</td>\n",
       "      <td>4.000917e-04</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>8.476443e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.4, 'max_lea...</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.302186</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.003200</td>\n",
       "      <td>3.992348e-04</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>3.995420e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.6, 'max_lea...</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.299071</td>\n",
       "      <td>0.016020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0.004001</td>\n",
       "      <td>6.317379e-04</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>4.901164e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 11, 'max_features': 0.4, 'max_le...</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.295738</td>\n",
       "      <td>0.020149</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.005001</td>\n",
       "      <td>1.414516e-03</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>4.911909e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.8, 'max_lea...</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.295683</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.003399</td>\n",
       "      <td>4.897084e-04</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>4.906616e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.4, 'max_lea...</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.295683</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>6.468134e-07</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>7.776979e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.2, 'max_lea...</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.295683</td>\n",
       "      <td>0.012364</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>0.003200</td>\n",
       "      <td>3.986461e-04</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.108069e-06</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.2, 'max_le...</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.292514</td>\n",
       "      <td>0.030301</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "355       0.004002  8.983134e-04         0.003200    4.015974e-04   \n",
       "663       0.003202  7.492865e-04         0.001799    3.992348e-04   \n",
       "783       0.003000  7.835234e-07         0.002000    1.072619e-06   \n",
       "218       0.002800  4.000917e-04         0.002000    8.476443e-07   \n",
       "299       0.003200  3.992348e-04         0.002200    3.995420e-04   \n",
       "658       0.004001  6.317379e-04         0.002399    4.901164e-04   \n",
       "571       0.005001  1.414516e-03         0.003601    4.911909e-04   \n",
       "475       0.003399  4.897084e-04         0.002401    4.906616e-04   \n",
       "133       0.003000  6.468134e-07         0.002000    7.776979e-07   \n",
       "586       0.003200  3.986461e-04         0.002000    1.108069e-06   \n",
       "\n",
       "    param_max_depth param_max_features param_max_leaf_nodes  \\\n",
       "355               6                0.6                   20   \n",
       "663              11                0.4                   30   \n",
       "783              13                0.2                   50   \n",
       "218               4                0.4                   40   \n",
       "299               5                0.6                   40   \n",
       "658              11                0.4                   20   \n",
       "571               9                0.8                   40   \n",
       "475               8                0.4                   40   \n",
       "133               3                0.2                   30   \n",
       "586              10                0.2                   40   \n",
       "\n",
       "    param_min_samples_leaf                                             params  \\\n",
       "355                     10  {'max_depth': 6, 'max_features': 0.6, 'max_lea...   \n",
       "663                     10  {'max_depth': 11, 'max_features': 0.4, 'max_le...   \n",
       "783                     10  {'max_depth': 13, 'max_features': 0.2, 'max_le...   \n",
       "218                      5  {'max_depth': 4, 'max_features': 0.4, 'max_lea...   \n",
       "299                     10  {'max_depth': 5, 'max_features': 0.6, 'max_lea...   \n",
       "658                      5  {'max_depth': 11, 'max_features': 0.4, 'max_le...   \n",
       "571                     10  {'max_depth': 9, 'max_features': 0.8, 'max_lea...   \n",
       "475                     10  {'max_depth': 8, 'max_features': 0.4, 'max_lea...   \n",
       "133                      2  {'max_depth': 3, 'max_features': 0.2, 'max_lea...   \n",
       "586                      5  {'max_depth': 10, 'max_features': 0.2, 'max_le...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "355           0.278689           0.316667           0.316667   \n",
       "663           0.278689           0.266667           0.366667   \n",
       "783           0.311475           0.300000           0.350000   \n",
       "218           0.344262           0.300000           0.300000   \n",
       "299           0.278689           0.316667           0.300000   \n",
       "658           0.278689           0.300000           0.316667   \n",
       "571           0.295082           0.266667           0.316667   \n",
       "475           0.295082           0.300000           0.300000   \n",
       "133           0.295082           0.300000           0.316667   \n",
       "586           0.245902           0.316667           0.333333   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "355           0.333333           0.316667         0.312404        0.018051   \n",
       "663           0.333333           0.283333         0.305738        0.038037   \n",
       "783           0.283333           0.266667         0.302295        0.028264   \n",
       "218           0.266667           0.300000         0.302186        0.024683   \n",
       "299           0.316667           0.283333         0.299071        0.016020   \n",
       "658           0.316667           0.266667         0.295738        0.020149   \n",
       "571           0.316667           0.283333         0.295683        0.019367   \n",
       "475           0.283333           0.300000         0.295683        0.006462   \n",
       "133           0.283333           0.283333         0.295683        0.012364   \n",
       "586           0.283333           0.283333         0.292514        0.030301   \n",
       "\n",
       "     rank_test_score  \n",
       "355                1  \n",
       "663                2  \n",
       "783                3  \n",
       "218                4  \n",
       "299                5  \n",
       "658                6  \n",
       "571                7  \n",
       "475                8  \n",
       "133                8  \n",
       "586               10  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(10)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4983388704318937\n",
      "0.24806201550387597\n"
     ]
    }
   ],
   "source": [
    "clf=tree.DecisionTreeClassifier(max_depth= 8, max_features= 0.2, random_state=42)\n",
    "# clf=tree.DecisionTreeClassifier(max_depth= 8, max_leaf_nodes=30,max_features= 0.2,  min_samples_leaf= 2, random_state=42)\n",
    "clf=clf.fit(X_train, yCat_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, yCat_train))\n",
    "print(clf.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3488372093023256\n",
      "0.26356589147286824\n"
     ]
    }
   ],
   "source": [
    "# clf=tree.DecisionTreeClassifier(max_depth= 10, max_features= 0.4, random_state=42)\n",
    "clf=tree.DecisionTreeClassifier(max_depth= 8, max_leaf_nodes=40,max_features= 0.2,  min_samples_leaf= 5, random_state=42)\n",
    "clf=clf.fit(X_train, yCat_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, yCat_train))\n",
    "print(clf.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34551495016611294\n",
      "0.2248062015503876\n"
     ]
    }
   ],
   "source": [
    "# clf=tree.DecisionTreeClassifier(max_depth= 10, max_features= 0.4, random_state=42)\n",
    "clf=tree.DecisionTreeClassifier(max_depth= 10, max_leaf_nodes=30,max_features= 0.4,  min_samples_leaf= 10, random_state=42)\n",
    "clf=clf.fit(X_train, yCat_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, yCat_train))\n",
    "print(clf.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34551495016611294\n",
      "0.24031007751937986\n"
     ]
    }
   ],
   "source": [
    "# clf=tree.DecisionTreeClassifier(max_depth= 4, max_leaf_nodes=50,max_features= 0.8,  min_samples_leaf= 5, random_state=42)\n",
    "clf=tree.DecisionTreeClassifier(max_depth= 4,max_features= 0.8, random_state=42)\n",
    "clf=clf.fit(X_train, yCat_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(clf.score(X_train, yCat_train))\n",
    "print(clf.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the smaller max depth we don't need the others to not overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9184678135274456\n",
      "0.365007466476005\n",
      "Training RMSE:  10.341672736701419\n",
      "Test RMSE:  36.390358253967044\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestRegressor(random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6482448441969404\n",
      "0.3144738321195727\n",
      "Training RMSE:  21.48060364588158\n",
      "Test RMSE:  37.81064103882696\n"
     ]
    }
   ],
   "source": [
    "#these are the best for decision trees so I used these\n",
    "clf_rf = RandomForestRegressor(max_depth=6, max_features= 0.4, random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 0.4,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=9, max_features=0.4, n_estimators=200,\n",
      "                      random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4835204395671754"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_depth':np.arange(4, 10),\n",
    "              'max_features':[0.2,0.4,0.6,0.8],\n",
    "              'n_estimators': [10,50,100,200,300,500,1000]}\n",
    "grid_search = GridSearchCV(clf_rf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.374330</td>\n",
       "      <td>0.031983</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.475502</td>\n",
       "      <td>0.279282</td>\n",
       "      <td>0.623909</td>\n",
       "      <td>0.527195</td>\n",
       "      <td>0.511715</td>\n",
       "      <td>0.483520</td>\n",
       "      <td>0.113304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.101607</td>\n",
       "      <td>0.008429</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.469091</td>\n",
       "      <td>0.294694</td>\n",
       "      <td>0.617151</td>\n",
       "      <td>0.510980</td>\n",
       "      <td>0.516632</td>\n",
       "      <td>0.481710</td>\n",
       "      <td>0.105408</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.569442</td>\n",
       "      <td>0.086988</td>\n",
       "      <td>0.030403</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.477218</td>\n",
       "      <td>0.273517</td>\n",
       "      <td>0.622115</td>\n",
       "      <td>0.528381</td>\n",
       "      <td>0.497338</td>\n",
       "      <td>0.479714</td>\n",
       "      <td>0.114438</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1.993651</td>\n",
       "      <td>0.121234</td>\n",
       "      <td>0.084606</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.476136</td>\n",
       "      <td>0.265226</td>\n",
       "      <td>0.629216</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.497980</td>\n",
       "      <td>0.479101</td>\n",
       "      <td>0.119106</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.172107</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>0.062004</td>\n",
       "      <td>0.010409</td>\n",
       "      <td>9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.475997</td>\n",
       "      <td>0.267316</td>\n",
       "      <td>0.625207</td>\n",
       "      <td>0.532145</td>\n",
       "      <td>0.491269</td>\n",
       "      <td>0.478387</td>\n",
       "      <td>0.117617</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.198015</td>\n",
       "      <td>0.018582</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.469742</td>\n",
       "      <td>0.274660</td>\n",
       "      <td>0.619878</td>\n",
       "      <td>0.501405</td>\n",
       "      <td>0.507535</td>\n",
       "      <td>0.474644</td>\n",
       "      <td>0.112168</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.555244</td>\n",
       "      <td>0.074858</td>\n",
       "      <td>0.027202</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.508531</td>\n",
       "      <td>0.230947</td>\n",
       "      <td>0.638174</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.475705</td>\n",
       "      <td>0.472490</td>\n",
       "      <td>0.132999</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.899068</td>\n",
       "      <td>0.051954</td>\n",
       "      <td>0.048403</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.504959</td>\n",
       "      <td>0.235261</td>\n",
       "      <td>0.639550</td>\n",
       "      <td>0.507207</td>\n",
       "      <td>0.469663</td>\n",
       "      <td>0.471328</td>\n",
       "      <td>0.131489</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.926006</td>\n",
       "      <td>0.357234</td>\n",
       "      <td>0.088607</td>\n",
       "      <td>0.019948</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.503279</td>\n",
       "      <td>0.238648</td>\n",
       "      <td>0.638251</td>\n",
       "      <td>0.504916</td>\n",
       "      <td>0.469685</td>\n",
       "      <td>0.470956</td>\n",
       "      <td>0.129734</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.427733</td>\n",
       "      <td>0.061039</td>\n",
       "      <td>0.022402</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.506260</td>\n",
       "      <td>0.228603</td>\n",
       "      <td>0.640117</td>\n",
       "      <td>0.501747</td>\n",
       "      <td>0.473290</td>\n",
       "      <td>0.470004</td>\n",
       "      <td>0.133825</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2.200377</td>\n",
       "      <td>0.225655</td>\n",
       "      <td>0.098807</td>\n",
       "      <td>0.014344</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.454276</td>\n",
       "      <td>0.272376</td>\n",
       "      <td>0.608891</td>\n",
       "      <td>0.506213</td>\n",
       "      <td>0.504064</td>\n",
       "      <td>0.469164</td>\n",
       "      <td>0.110509</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.084206</td>\n",
       "      <td>0.009303</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.443198</td>\n",
       "      <td>0.255719</td>\n",
       "      <td>0.639879</td>\n",
       "      <td>0.519465</td>\n",
       "      <td>0.480298</td>\n",
       "      <td>0.467712</td>\n",
       "      <td>0.124916</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.085204</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.475047</td>\n",
       "      <td>0.233107</td>\n",
       "      <td>0.648350</td>\n",
       "      <td>0.466320</td>\n",
       "      <td>0.514911</td>\n",
       "      <td>0.467547</td>\n",
       "      <td>0.134129</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.951073</td>\n",
       "      <td>0.066192</td>\n",
       "      <td>0.047003</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.450428</td>\n",
       "      <td>0.267870</td>\n",
       "      <td>0.608952</td>\n",
       "      <td>0.506925</td>\n",
       "      <td>0.489423</td>\n",
       "      <td>0.464720</td>\n",
       "      <td>0.111488</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.469069</td>\n",
       "      <td>0.129848</td>\n",
       "      <td>0.027801</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.444542</td>\n",
       "      <td>0.258653</td>\n",
       "      <td>0.622193</td>\n",
       "      <td>0.499305</td>\n",
       "      <td>0.495155</td>\n",
       "      <td>0.463970</td>\n",
       "      <td>0.118143</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.684652</td>\n",
       "      <td>0.100443</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.442251</td>\n",
       "      <td>0.270576</td>\n",
       "      <td>0.613589</td>\n",
       "      <td>0.508645</td>\n",
       "      <td>0.484662</td>\n",
       "      <td>0.463945</td>\n",
       "      <td>0.111967</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.806137</td>\n",
       "      <td>0.074669</td>\n",
       "      <td>0.088807</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.482467</td>\n",
       "      <td>0.250260</td>\n",
       "      <td>0.631565</td>\n",
       "      <td>0.476056</td>\n",
       "      <td>0.475126</td>\n",
       "      <td>0.463095</td>\n",
       "      <td>0.121958</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.945348</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.479357</td>\n",
       "      <td>0.246557</td>\n",
       "      <td>0.635695</td>\n",
       "      <td>0.472481</td>\n",
       "      <td>0.478487</td>\n",
       "      <td>0.462515</td>\n",
       "      <td>0.124312</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.210723</td>\n",
       "      <td>0.043544</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.485940</td>\n",
       "      <td>0.241894</td>\n",
       "      <td>0.624500</td>\n",
       "      <td>0.460711</td>\n",
       "      <td>0.496537</td>\n",
       "      <td>0.461916</td>\n",
       "      <td>0.123791</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.228216</td>\n",
       "      <td>0.050779</td>\n",
       "      <td>0.013402</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.443964</td>\n",
       "      <td>0.253884</td>\n",
       "      <td>0.630883</td>\n",
       "      <td>0.492604</td>\n",
       "      <td>0.487928</td>\n",
       "      <td>0.461852</td>\n",
       "      <td>0.121464</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.684451</td>\n",
       "      <td>0.162695</td>\n",
       "      <td>0.031203</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.482263</td>\n",
       "      <td>0.240102</td>\n",
       "      <td>0.632741</td>\n",
       "      <td>0.475672</td>\n",
       "      <td>0.475667</td>\n",
       "      <td>0.461289</td>\n",
       "      <td>0.125835</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.077805</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.456640</td>\n",
       "      <td>0.279710</td>\n",
       "      <td>0.594109</td>\n",
       "      <td>0.466605</td>\n",
       "      <td>0.508863</td>\n",
       "      <td>0.461185</td>\n",
       "      <td>0.102884</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.479741</td>\n",
       "      <td>0.147907</td>\n",
       "      <td>0.025402</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.530765</td>\n",
       "      <td>0.234755</td>\n",
       "      <td>0.639592</td>\n",
       "      <td>0.475549</td>\n",
       "      <td>0.420899</td>\n",
       "      <td>0.460312</td>\n",
       "      <td>0.133990</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.452636</td>\n",
       "      <td>0.061671</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.480845</td>\n",
       "      <td>0.247411</td>\n",
       "      <td>0.625094</td>\n",
       "      <td>0.462073</td>\n",
       "      <td>0.485161</td>\n",
       "      <td>0.460117</td>\n",
       "      <td>0.121261</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.860150</td>\n",
       "      <td>0.130678</td>\n",
       "      <td>0.093208</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.431269</td>\n",
       "      <td>0.286967</td>\n",
       "      <td>0.586418</td>\n",
       "      <td>0.519589</td>\n",
       "      <td>0.474540</td>\n",
       "      <td>0.459757</td>\n",
       "      <td>0.100508</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.067262</td>\n",
       "      <td>0.200388</td>\n",
       "      <td>0.045804</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.524292</td>\n",
       "      <td>0.231698</td>\n",
       "      <td>0.644269</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>0.399196</td>\n",
       "      <td>0.459383</td>\n",
       "      <td>0.138064</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.632448</td>\n",
       "      <td>0.060921</td>\n",
       "      <td>0.031803</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.526984</td>\n",
       "      <td>0.227227</td>\n",
       "      <td>0.642639</td>\n",
       "      <td>0.500590</td>\n",
       "      <td>0.392917</td>\n",
       "      <td>0.458071</td>\n",
       "      <td>0.140111</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.181814</td>\n",
       "      <td>0.023098</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.498697</td>\n",
       "      <td>0.248605</td>\n",
       "      <td>0.619578</td>\n",
       "      <td>0.475802</td>\n",
       "      <td>0.445585</td>\n",
       "      <td>0.457653</td>\n",
       "      <td>0.120067</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.438432</td>\n",
       "      <td>0.033007</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.510072</td>\n",
       "      <td>0.249525</td>\n",
       "      <td>0.633128</td>\n",
       "      <td>0.470279</td>\n",
       "      <td>0.421891</td>\n",
       "      <td>0.456979</td>\n",
       "      <td>0.125134</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.895748</td>\n",
       "      <td>0.169067</td>\n",
       "      <td>0.090808</td>\n",
       "      <td>0.012352</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.520645</td>\n",
       "      <td>0.233994</td>\n",
       "      <td>0.641074</td>\n",
       "      <td>0.488881</td>\n",
       "      <td>0.399603</td>\n",
       "      <td>0.456839</td>\n",
       "      <td>0.135629</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "150       0.374330      0.031983         0.022601        0.003877   \n",
       "148       0.101607      0.008429         0.007401        0.000490   \n",
       "151       0.569442      0.086988         0.030403        0.006087   \n",
       "153       1.993651      0.121234         0.084606        0.009521   \n",
       "152       1.172107      0.155234         0.062004        0.010409   \n",
       "149       0.198015      0.018582         0.011800        0.001167   \n",
       "158       0.555244      0.074858         0.027202        0.004166   \n",
       "159       0.899068      0.051954         0.048403        0.004318   \n",
       "160       1.926006      0.357234         0.088607        0.019948   \n",
       "157       0.427733      0.061039         0.022402        0.003720   \n",
       "125       2.200377      0.225655         0.098807        0.014344   \n",
       "120       0.084206      0.009303         0.006600        0.000801   \n",
       "127       0.085204      0.005879         0.006601        0.000800   \n",
       "124       0.951073      0.066192         0.047003        0.003633   \n",
       "122       0.469069      0.129848         0.027801        0.006306   \n",
       "123       0.684652      0.100443         0.033603        0.003720   \n",
       "132       1.806137      0.074669         0.088807        0.004308   \n",
       "131       0.945348      0.030598         0.046004        0.006450   \n",
       "128       0.210723      0.043544         0.012401        0.002578   \n",
       "121       0.228216      0.050779         0.013402        0.001854   \n",
       "130       0.684451      0.162695         0.031203        0.003310   \n",
       "92        0.077805      0.004666         0.006001        0.000002   \n",
       "164       0.479741      0.147907         0.025402        0.003007   \n",
       "129       0.452636      0.061671         0.025800        0.004833   \n",
       "146       1.860150      0.130678         0.093208        0.011072   \n",
       "166       1.067262      0.200388         0.045804        0.008566   \n",
       "165       0.632448      0.060921         0.031803        0.006494   \n",
       "135       0.181814      0.023098         0.010400        0.001356   \n",
       "136       0.438432      0.033007         0.021002        0.001999   \n",
       "167       1.895748      0.169067         0.090808        0.012352   \n",
       "\n",
       "    param_max_depth param_max_features param_n_estimators  \\\n",
       "150               9                0.4                200   \n",
       "148               9                0.4                 50   \n",
       "151               9                0.4                300   \n",
       "153               9                0.4               1000   \n",
       "152               9                0.4                500   \n",
       "149               9                0.4                100   \n",
       "158               9                0.6                300   \n",
       "159               9                0.6                500   \n",
       "160               9                0.6               1000   \n",
       "157               9                0.6                200   \n",
       "125               8                0.4               1000   \n",
       "120               8                0.4                 50   \n",
       "127               8                0.6                 50   \n",
       "124               8                0.4                500   \n",
       "122               8                0.4                200   \n",
       "123               8                0.4                300   \n",
       "132               8                0.6               1000   \n",
       "131               8                0.6                500   \n",
       "128               8                0.6                100   \n",
       "121               8                0.4                100   \n",
       "130               8                0.6                300   \n",
       "92                7                0.4                 50   \n",
       "164               9                0.8                200   \n",
       "129               8                0.6                200   \n",
       "146               9                0.2               1000   \n",
       "166               9                0.8                500   \n",
       "165               9                0.8                300   \n",
       "135               8                0.8                100   \n",
       "136               8                0.8                200   \n",
       "167               9                0.8               1000   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "150  {'max_depth': 9, 'max_features': 0.4, 'n_estim...           0.475502   \n",
       "148  {'max_depth': 9, 'max_features': 0.4, 'n_estim...           0.469091   \n",
       "151  {'max_depth': 9, 'max_features': 0.4, 'n_estim...           0.477218   \n",
       "153  {'max_depth': 9, 'max_features': 0.4, 'n_estim...           0.476136   \n",
       "152  {'max_depth': 9, 'max_features': 0.4, 'n_estim...           0.475997   \n",
       "149  {'max_depth': 9, 'max_features': 0.4, 'n_estim...           0.469742   \n",
       "158  {'max_depth': 9, 'max_features': 0.6, 'n_estim...           0.508531   \n",
       "159  {'max_depth': 9, 'max_features': 0.6, 'n_estim...           0.504959   \n",
       "160  {'max_depth': 9, 'max_features': 0.6, 'n_estim...           0.503279   \n",
       "157  {'max_depth': 9, 'max_features': 0.6, 'n_estim...           0.506260   \n",
       "125  {'max_depth': 8, 'max_features': 0.4, 'n_estim...           0.454276   \n",
       "120  {'max_depth': 8, 'max_features': 0.4, 'n_estim...           0.443198   \n",
       "127  {'max_depth': 8, 'max_features': 0.6, 'n_estim...           0.475047   \n",
       "124  {'max_depth': 8, 'max_features': 0.4, 'n_estim...           0.450428   \n",
       "122  {'max_depth': 8, 'max_features': 0.4, 'n_estim...           0.444542   \n",
       "123  {'max_depth': 8, 'max_features': 0.4, 'n_estim...           0.442251   \n",
       "132  {'max_depth': 8, 'max_features': 0.6, 'n_estim...           0.482467   \n",
       "131  {'max_depth': 8, 'max_features': 0.6, 'n_estim...           0.479357   \n",
       "128  {'max_depth': 8, 'max_features': 0.6, 'n_estim...           0.485940   \n",
       "121  {'max_depth': 8, 'max_features': 0.4, 'n_estim...           0.443964   \n",
       "130  {'max_depth': 8, 'max_features': 0.6, 'n_estim...           0.482263   \n",
       "92   {'max_depth': 7, 'max_features': 0.4, 'n_estim...           0.456640   \n",
       "164  {'max_depth': 9, 'max_features': 0.8, 'n_estim...           0.530765   \n",
       "129  {'max_depth': 8, 'max_features': 0.6, 'n_estim...           0.480845   \n",
       "146  {'max_depth': 9, 'max_features': 0.2, 'n_estim...           0.431269   \n",
       "166  {'max_depth': 9, 'max_features': 0.8, 'n_estim...           0.524292   \n",
       "165  {'max_depth': 9, 'max_features': 0.8, 'n_estim...           0.526984   \n",
       "135  {'max_depth': 8, 'max_features': 0.8, 'n_estim...           0.498697   \n",
       "136  {'max_depth': 8, 'max_features': 0.8, 'n_estim...           0.510072   \n",
       "167  {'max_depth': 9, 'max_features': 0.8, 'n_estim...           0.520645   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "150           0.279282           0.623909           0.527195   \n",
       "148           0.294694           0.617151           0.510980   \n",
       "151           0.273517           0.622115           0.528381   \n",
       "153           0.265226           0.629216           0.526948   \n",
       "152           0.267316           0.625207           0.532145   \n",
       "149           0.274660           0.619878           0.501405   \n",
       "158           0.230947           0.638174           0.509091   \n",
       "159           0.235261           0.639550           0.507207   \n",
       "160           0.238648           0.638251           0.504916   \n",
       "157           0.228603           0.640117           0.501747   \n",
       "125           0.272376           0.608891           0.506213   \n",
       "120           0.255719           0.639879           0.519465   \n",
       "127           0.233107           0.648350           0.466320   \n",
       "124           0.267870           0.608952           0.506925   \n",
       "122           0.258653           0.622193           0.499305   \n",
       "123           0.270576           0.613589           0.508645   \n",
       "132           0.250260           0.631565           0.476056   \n",
       "131           0.246557           0.635695           0.472481   \n",
       "128           0.241894           0.624500           0.460711   \n",
       "121           0.253884           0.630883           0.492604   \n",
       "130           0.240102           0.632741           0.475672   \n",
       "92            0.279710           0.594109           0.466605   \n",
       "164           0.234755           0.639592           0.475549   \n",
       "129           0.247411           0.625094           0.462073   \n",
       "146           0.286967           0.586418           0.519589   \n",
       "166           0.231698           0.644269           0.497462   \n",
       "165           0.227227           0.642639           0.500590   \n",
       "135           0.248605           0.619578           0.475802   \n",
       "136           0.249525           0.633128           0.470279   \n",
       "167           0.233994           0.641074           0.488881   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "150           0.511715         0.483520        0.113304                1  \n",
       "148           0.516632         0.481710        0.105408                2  \n",
       "151           0.497338         0.479714        0.114438                3  \n",
       "153           0.497980         0.479101        0.119106                4  \n",
       "152           0.491269         0.478387        0.117617                5  \n",
       "149           0.507535         0.474644        0.112168                6  \n",
       "158           0.475705         0.472490        0.132999                7  \n",
       "159           0.469663         0.471328        0.131489                8  \n",
       "160           0.469685         0.470956        0.129734                9  \n",
       "157           0.473290         0.470004        0.133825               10  \n",
       "125           0.504064         0.469164        0.110509               11  \n",
       "120           0.480298         0.467712        0.124916               12  \n",
       "127           0.514911         0.467547        0.134129               13  \n",
       "124           0.489423         0.464720        0.111488               14  \n",
       "122           0.495155         0.463970        0.118143               15  \n",
       "123           0.484662         0.463945        0.111967               16  \n",
       "132           0.475126         0.463095        0.121958               17  \n",
       "131           0.478487         0.462515        0.124312               18  \n",
       "128           0.496537         0.461916        0.123791               19  \n",
       "121           0.487928         0.461852        0.121464               20  \n",
       "130           0.475667         0.461289        0.125835               21  \n",
       "92            0.508863         0.461185        0.102884               22  \n",
       "164           0.420899         0.460312        0.133990               23  \n",
       "129           0.485161         0.460117        0.121261               24  \n",
       "146           0.474540         0.459757        0.100508               25  \n",
       "166           0.399196         0.459383        0.138064               26  \n",
       "165           0.392917         0.458071        0.140111               27  \n",
       "135           0.445585         0.457653        0.120067               28  \n",
       "136           0.421891         0.456979        0.125134               29  \n",
       "167           0.399603         0.456839        0.135629               30  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(30)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8362808411435276\n",
      "0.394063180290253\n",
      "Training RMSE:  14.654668478380334\n",
      "Test RMSE:  35.54804271499406\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestRegressor(max_depth=9, max_features= 0.4, n_estimators=200,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8403700499832222\n",
      "0.39657321604835716\n",
      "Training RMSE:  14.4704965703458\n",
      "Test RMSE:  35.47433911193609\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestRegressor(max_depth=9, max_features= 0.4, n_estimators=1000,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8565318598934387\n",
      "0.3836118051699863\n",
      "Training RMSE:  13.718416365779932\n",
      "Test RMSE:  35.85330354366148\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestRegressor(max_depth=9, max_features= 0.6, n_estimators=1000,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8412955158322049\n",
      "0.39674754684700253\n",
      "Training RMSE:  14.428488735800183\n",
      "Test RMSE:  35.469214449956574\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestRegressor(max_depth=9, max_features= 0.4, n_estimators=2000,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8410060180364674\n",
      "0.3978976564111224\n",
      "Training RMSE:  14.441642467989873\n",
      "Test RMSE:  35.435387032881124\n"
     ]
    }
   ],
   "source": [
    "#BEST\n",
    "clf_rf = RandomForestRegressor(max_depth=9, max_features= 0.4, n_estimators=5000,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))\n",
    "# in order to address the overfit I would have to drastially underfit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_test, rf_y_test_pred, c='crimson')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "\n",
    "p1 = max(max(rf_y_test_pred), max(y_test))\n",
    "p2 = min(min(rf_y_test_pred), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7335340234819243\n",
      "0.3639444181972208\n",
      "Training RMSE:  18.695932353776428\n",
      "Test RMSE:  36.420806273884516\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestRegressor(max_depth=7, max_features= 0.4, n_estimators=5000,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6615669584107557\n",
      "0.3355258613829575\n",
      "Training RMSE:  21.069907275130454\n",
      "Test RMSE:  37.2255448653223\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestRegressor(max_depth=6, max_features= 0.4, n_estimators=5000,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6973719993826071\n",
      "0.332728757902369\n",
      "Training RMSE:  19.924195759262194\n",
      "Test RMSE:  37.303813038549876\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestRegressor(max_depth=6, max_features= 0.6, n_estimators=5000,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2671997181108273\n",
      "0.15008816634375755\n",
      "Training RMSE:  31.00409505238349\n",
      "Test RMSE:  42.10066539298613\n"
     ]
    }
   ],
   "source": [
    "#Addressing overfit but the cost in RMSE we get a high difference \n",
    "clf_rf = RandomForestRegressor(max_depth=2, max_features= 0.4, n_estimators=5000,random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "\n",
    "print(clf_rf.score(X_train, y_train))\n",
    "print(clf_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, rf_y_train_pred)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,rf_y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9667774086378738\n",
      "0.2248062015503876\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf.fit(X_train, yCat_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, yCat_train))\n",
    "print(clf_rf.score(X_test, yCat_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=5, max_features=0.6, random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12967213114754098"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_depth':np.arange(4, 10),\n",
    "              'max_features':[0.2,0.4,0.6,0.8],\n",
    "              'n_estimators': [10,50,100,200,300,500,1000]}\n",
    "grid_search = GridSearchCV(clf_rf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.205015</td>\n",
       "      <td>0.036257</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.129672</td>\n",
       "      <td>0.022561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.020618</td>\n",
       "      <td>0.200357</td>\n",
       "      <td>0.158614</td>\n",
       "      <td>0.036150</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.126339</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.479837</td>\n",
       "      <td>0.059238</td>\n",
       "      <td>0.032801</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.123005</td>\n",
       "      <td>0.017453</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.430734</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>0.029803</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.123005</td>\n",
       "      <td>0.020389</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.616246</td>\n",
       "      <td>0.061129</td>\n",
       "      <td>0.042404</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.123005</td>\n",
       "      <td>0.022953</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.425442</td>\n",
       "      <td>0.045274</td>\n",
       "      <td>0.032002</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.123005</td>\n",
       "      <td>0.017453</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.106483</td>\n",
       "      <td>0.033172</td>\n",
       "      <td>0.073804</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.392182</td>\n",
       "      <td>0.150349</td>\n",
       "      <td>0.144209</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.225192</td>\n",
       "      <td>0.350173</td>\n",
       "      <td>0.143410</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.968874</td>\n",
       "      <td>0.067404</td>\n",
       "      <td>0.070406</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.100609</td>\n",
       "      <td>0.018121</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.383229</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>0.025497</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.117131</td>\n",
       "      <td>0.176327</td>\n",
       "      <td>0.144011</td>\n",
       "      <td>0.017357</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.886267</td>\n",
       "      <td>0.046816</td>\n",
       "      <td>0.064406</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.676251</td>\n",
       "      <td>0.050693</td>\n",
       "      <td>0.044604</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.600246</td>\n",
       "      <td>0.046251</td>\n",
       "      <td>0.042805</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.244018</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>0.016002</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2.365369</td>\n",
       "      <td>0.083365</td>\n",
       "      <td>0.146211</td>\n",
       "      <td>0.008841</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1.177090</td>\n",
       "      <td>0.096599</td>\n",
       "      <td>0.073805</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.895966</td>\n",
       "      <td>0.128172</td>\n",
       "      <td>0.068005</td>\n",
       "      <td>0.014887</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.601111</td>\n",
       "      <td>0.042614</td>\n",
       "      <td>0.039205</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2.696129</td>\n",
       "      <td>0.319411</td>\n",
       "      <td>0.176414</td>\n",
       "      <td>0.019746</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.622150</td>\n",
       "      <td>0.141648</td>\n",
       "      <td>0.042202</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.204215</td>\n",
       "      <td>0.017338</td>\n",
       "      <td>0.016002</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.116339</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.176490</td>\n",
       "      <td>0.097445</td>\n",
       "      <td>0.072509</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.116339</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2.193367</td>\n",
       "      <td>0.145096</td>\n",
       "      <td>0.161814</td>\n",
       "      <td>0.020224</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116339</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.971604</td>\n",
       "      <td>0.195433</td>\n",
       "      <td>0.145610</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.116339</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.013382</td>\n",
       "      <td>0.057367</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.116339</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.199214</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>0.017602</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.116339</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.041613</td>\n",
       "      <td>0.045204</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.116339</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "44       0.205015      0.036257         0.016602        0.003383   \n",
       "41       2.020618      0.200357         0.158614        0.036150   \n",
       "80       0.479837      0.059238         0.032801        0.004955   \n",
       "38       0.430734      0.014608         0.029803        0.002401   \n",
       "46       0.616246      0.061129         0.042404        0.006344   \n",
       "45       0.425442      0.045274         0.032002        0.003522   \n",
       "26       1.106483      0.033172         0.073804        0.007731   \n",
       "27       2.392182      0.150349         0.144209        0.013334   \n",
       "20       2.225192      0.350173         0.143410        0.007474   \n",
       "19       0.968874      0.067404         0.070406        0.005748   \n",
       "50       0.100609      0.018121         0.008999        0.001263   \n",
       "17       0.383229      0.024360         0.025497        0.002758   \n",
       "48       2.117131      0.176327         0.144011        0.017357   \n",
       "47       0.886267      0.046816         0.064406        0.005352   \n",
       "25       0.676251      0.050693         0.044604        0.004758   \n",
       "39       0.600246      0.046251         0.042805        0.005154   \n",
       "79       0.244018      0.027490         0.016002        0.002899   \n",
       "76       2.365369      0.083365         0.146211        0.008841   \n",
       "75       1.177090      0.096599         0.073805        0.008281   \n",
       "74       0.895966      0.128172         0.068005        0.014887   \n",
       "73       0.601111      0.042614         0.039205        0.011443   \n",
       "69       2.696129      0.319411         0.176414        0.019746   \n",
       "24       0.622150      0.141648         0.042202        0.010108   \n",
       "37       0.204215      0.017338         0.016002        0.002191   \n",
       "40       1.176490      0.097445         0.072509        0.011684   \n",
       "83       2.193367      0.145096         0.161814        0.020224   \n",
       "55       1.971604      0.195433         0.145610        0.023906   \n",
       "54       1.013382      0.057367         0.066004        0.006693   \n",
       "9        0.199214      0.014756         0.017602        0.002245   \n",
       "81       0.700111      0.041613         0.045204        0.005707   \n",
       "\n",
       "   param_max_depth param_max_features param_n_estimators  \\\n",
       "44               5                0.6                100   \n",
       "41               5                0.4               1000   \n",
       "80               6                0.8                200   \n",
       "38               5                0.4                200   \n",
       "46               5                0.6                300   \n",
       "45               5                0.6                200   \n",
       "26               4                0.8                500   \n",
       "27               4                0.8               1000   \n",
       "20               4                0.6               1000   \n",
       "19               4                0.6                500   \n",
       "50               5                0.8                 50   \n",
       "17               4                0.6                200   \n",
       "48               5                0.6               1000   \n",
       "47               5                0.6                500   \n",
       "25               4                0.8                300   \n",
       "39               5                0.4                300   \n",
       "79               6                0.8                100   \n",
       "76               6                0.6               1000   \n",
       "75               6                0.6                500   \n",
       "74               6                0.6                300   \n",
       "73               6                0.6                200   \n",
       "69               6                0.4               1000   \n",
       "24               4                0.8                200   \n",
       "37               5                0.4                100   \n",
       "40               5                0.4                500   \n",
       "83               6                0.8               1000   \n",
       "55               5                0.8               1000   \n",
       "54               5                0.8                500   \n",
       "9                4                0.4                100   \n",
       "81               6                0.8                300   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "44  {'max_depth': 5, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "41  {'max_depth': 5, 'max_features': 0.4, 'n_estim...           0.098361   \n",
       "80  {'max_depth': 6, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "38  {'max_depth': 5, 'max_features': 0.4, 'n_estim...           0.098361   \n",
       "46  {'max_depth': 5, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "45  {'max_depth': 5, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "26  {'max_depth': 4, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "27  {'max_depth': 4, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "20  {'max_depth': 4, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "19  {'max_depth': 4, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "50  {'max_depth': 5, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "17  {'max_depth': 4, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "48  {'max_depth': 5, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "47  {'max_depth': 5, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "25  {'max_depth': 4, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "39  {'max_depth': 5, 'max_features': 0.4, 'n_estim...           0.098361   \n",
       "79  {'max_depth': 6, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "76  {'max_depth': 6, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "75  {'max_depth': 6, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "74  {'max_depth': 6, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "73  {'max_depth': 6, 'max_features': 0.6, 'n_estim...           0.098361   \n",
       "69  {'max_depth': 6, 'max_features': 0.4, 'n_estim...           0.098361   \n",
       "24  {'max_depth': 4, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "37  {'max_depth': 5, 'max_features': 0.4, 'n_estim...           0.098361   \n",
       "40  {'max_depth': 5, 'max_features': 0.4, 'n_estim...           0.098361   \n",
       "83  {'max_depth': 6, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "55  {'max_depth': 5, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "54  {'max_depth': 5, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "9   {'max_depth': 4, 'max_features': 0.4, 'n_estim...           0.098361   \n",
       "81  {'max_depth': 6, 'max_features': 0.8, 'n_estim...           0.098361   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "44           0.116667           0.133333           0.133333   \n",
       "41           0.133333           0.116667           0.133333   \n",
       "80           0.116667           0.133333           0.116667   \n",
       "38           0.133333           0.100000           0.133333   \n",
       "46           0.116667           0.100000           0.150000   \n",
       "45           0.116667           0.116667           0.133333   \n",
       "26           0.116667           0.116667           0.116667   \n",
       "27           0.116667           0.116667           0.116667   \n",
       "20           0.116667           0.116667           0.116667   \n",
       "19           0.116667           0.116667           0.116667   \n",
       "50           0.116667           0.100000           0.133333   \n",
       "17           0.116667           0.116667           0.116667   \n",
       "48           0.116667           0.116667           0.116667   \n",
       "47           0.116667           0.116667           0.116667   \n",
       "25           0.116667           0.116667           0.116667   \n",
       "39           0.133333           0.100000           0.116667   \n",
       "79           0.116667           0.133333           0.100000   \n",
       "76           0.116667           0.133333           0.116667   \n",
       "75           0.116667           0.116667           0.133333   \n",
       "74           0.116667           0.116667           0.133333   \n",
       "73           0.116667           0.133333           0.100000   \n",
       "69           0.116667           0.116667           0.133333   \n",
       "24           0.116667           0.116667           0.116667   \n",
       "37           0.100000           0.116667           0.116667   \n",
       "40           0.116667           0.100000           0.116667   \n",
       "83           0.116667           0.133333           0.116667   \n",
       "55           0.116667           0.116667           0.100000   \n",
       "54           0.116667           0.116667           0.100000   \n",
       "9            0.116667           0.100000           0.116667   \n",
       "81           0.116667           0.116667           0.100000   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "44           0.166667         0.129672        0.022561                1  \n",
       "41           0.150000         0.126339        0.017516                2  \n",
       "80           0.150000         0.123005        0.017453                3  \n",
       "38           0.150000         0.123005        0.020389                3  \n",
       "46           0.150000         0.123005        0.022953                3  \n",
       "45           0.150000         0.123005        0.017453                3  \n",
       "26           0.150000         0.119672        0.016740                7  \n",
       "27           0.150000         0.119672        0.016740                7  \n",
       "20           0.150000         0.119672        0.016740                7  \n",
       "19           0.150000         0.119672        0.016740                7  \n",
       "50           0.150000         0.119672        0.019782                7  \n",
       "17           0.150000         0.119672        0.016740                7  \n",
       "48           0.150000         0.119672        0.016740                7  \n",
       "47           0.150000         0.119672        0.016740                7  \n",
       "25           0.150000         0.119672        0.016740                7  \n",
       "39           0.150000         0.119672        0.019782                7  \n",
       "79           0.150000         0.119672        0.019782                7  \n",
       "76           0.133333         0.119672        0.013004                7  \n",
       "75           0.133333         0.119672        0.013004                7  \n",
       "74           0.133333         0.119672        0.013004                7  \n",
       "73           0.150000         0.119672        0.019782                7  \n",
       "69           0.133333         0.119672        0.013004                7  \n",
       "24           0.150000         0.119672        0.016740                7  \n",
       "37           0.150000         0.116339        0.018566               24  \n",
       "40           0.150000         0.116339        0.018566               24  \n",
       "83           0.116667         0.116339        0.011067               24  \n",
       "55           0.150000         0.116339        0.018566               24  \n",
       "54           0.150000         0.116339        0.018566               24  \n",
       "9            0.150000         0.116339        0.018566               24  \n",
       "81           0.150000         0.116339        0.018566               24  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(30)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5016611295681063\n",
      "0.24806201550387597\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(max_depth=5, max_features=0.6, n_estimators=100,random_state=42)\n",
    "clf_rf.fit(X_train, yCat_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, yCat_train))\n",
    "print(clf_rf.score(X_test, yCat_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5116279069767442\n",
      "0.24031007751937986\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(max_depth=5, max_features=0.4, n_estimators=1000,random_state=42)\n",
    "clf_rf.fit(X_train, yCat_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, yCat_train))\n",
    "print(clf_rf.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6378737541528239\n",
      "0.26356589147286824\n"
     ]
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(max_depth=6, max_features=0.8, n_estimators=200,random_state=42)\n",
    "clf_rf.fit(X_train, yCat_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, yCat_train))\n",
    "print(clf_rf.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40863787375415284\n",
      "0.24031007751937986\n"
     ]
    }
   ],
   "source": [
    "#BEST\n",
    "clf_rf = RandomForestClassifier(max_depth=4, max_features=0.8, n_estimators=500,random_state=42)\n",
    "clf_rf.fit(X_train, yCat_train)\n",
    "rf_y_train_pred=clf_rf.predict(X_train)\n",
    "rf_y_test_pred=clf_rf.predict(X_test)\n",
    "print(clf_rf.score(X_train, yCat_train))\n",
    "print(clf_rf.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41797198649515654\n",
      "0.27982134324856556\n",
      "Training RMSE:  27.63110097089487\n",
      "Test RMSE:  38.75450061385719\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsRegressor()\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train,y_train_prediction)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,y_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(n_neighbors=10, p=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22819335079381073"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'n_neighbors': np.arange(1,40),\n",
    "            'p':[1,2]}\n",
    "grid_search= GridSearchCV(knn, param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.717640e-04</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.711459e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 10, 'p': 1}</td>\n",
       "      <td>0.229380</td>\n",
       "      <td>0.246877</td>\n",
       "      <td>0.208324</td>\n",
       "      <td>0.228193</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>8.778064e-07</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>5.150430e-07</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 9, 'p': 1}</td>\n",
       "      <td>0.244063</td>\n",
       "      <td>0.205266</td>\n",
       "      <td>0.203059</td>\n",
       "      <td>0.217463</td>\n",
       "      <td>0.018831</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.710899e-04</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 11, 'p': 1}</td>\n",
       "      <td>0.207859</td>\n",
       "      <td>0.220736</td>\n",
       "      <td>0.190853</td>\n",
       "      <td>0.206483</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002333</td>\n",
       "      <td>4.711457e-04</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.713171e-04</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 12, 'p': 1}</td>\n",
       "      <td>0.218679</td>\n",
       "      <td>0.181953</td>\n",
       "      <td>0.204883</td>\n",
       "      <td>0.201838</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003001</td>\n",
       "      <td>8.485379e-07</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>4.709228e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 13, 'p': 1}</td>\n",
       "      <td>0.212236</td>\n",
       "      <td>0.182456</td>\n",
       "      <td>0.208280</td>\n",
       "      <td>0.200991</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003004</td>\n",
       "      <td>6.072267e-06</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>5.886359e-06</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 7, 'p': 1}</td>\n",
       "      <td>0.260543</td>\n",
       "      <td>0.164098</td>\n",
       "      <td>0.174650</td>\n",
       "      <td>0.199764</td>\n",
       "      <td>0.043193</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.717638e-04</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>4.710899e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 8, 'p': 1}</td>\n",
       "      <td>0.242088</td>\n",
       "      <td>0.179581</td>\n",
       "      <td>0.168821</td>\n",
       "      <td>0.196830</td>\n",
       "      <td>0.032302</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.002334</td>\n",
       "      <td>4.709770e-04</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.703588e-04</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 18, 'p': 1}</td>\n",
       "      <td>0.208390</td>\n",
       "      <td>0.150668</td>\n",
       "      <td>0.220634</td>\n",
       "      <td>0.193231</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.002333</td>\n",
       "      <td>4.718206e-04</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.715952e-04</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 17, 'p': 1}</td>\n",
       "      <td>0.213273</td>\n",
       "      <td>0.151596</td>\n",
       "      <td>0.209493</td>\n",
       "      <td>0.191454</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003665</td>\n",
       "      <td>4.722138e-04</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.713714e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 6, 'p': 1}</td>\n",
       "      <td>0.257719</td>\n",
       "      <td>0.129691</td>\n",
       "      <td>0.175037</td>\n",
       "      <td>0.187483</td>\n",
       "      <td>0.053003</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003666</td>\n",
       "      <td>9.428531e-04</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.710902e-04</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 14, 'p': 1}</td>\n",
       "      <td>0.227398</td>\n",
       "      <td>0.133082</td>\n",
       "      <td>0.196499</td>\n",
       "      <td>0.185660</td>\n",
       "      <td>0.039260</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.699655e-04</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>1.246895e-03</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 19, 'p': 1}</td>\n",
       "      <td>0.196063</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.204649</td>\n",
       "      <td>0.185365</td>\n",
       "      <td>0.021487</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>1.247787e-03</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>4.495664e-07</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 16, 'p': 1}</td>\n",
       "      <td>0.210112</td>\n",
       "      <td>0.142128</td>\n",
       "      <td>0.203293</td>\n",
       "      <td>0.185178</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>3.371748e-07</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.716514e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 15, 'p': 1}</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.146465</td>\n",
       "      <td>0.179379</td>\n",
       "      <td>0.183520</td>\n",
       "      <td>0.032080</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>1.593426e-06</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 23, 'p': 1}</td>\n",
       "      <td>0.177023</td>\n",
       "      <td>0.158751</td>\n",
       "      <td>0.185984</td>\n",
       "      <td>0.173920</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003335</td>\n",
       "      <td>4.701373e-04</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>4.723286e-04</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 21, 'p': 1}</td>\n",
       "      <td>0.183026</td>\n",
       "      <td>0.162003</td>\n",
       "      <td>0.172124</td>\n",
       "      <td>0.172384</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.083865e-06</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>5.150430e-07</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 20, 'p': 1}</td>\n",
       "      <td>0.192427</td>\n",
       "      <td>0.141649</td>\n",
       "      <td>0.181823</td>\n",
       "      <td>0.171966</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002666</td>\n",
       "      <td>4.723258e-04</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.709770e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 5, 'p': 1}</td>\n",
       "      <td>0.237805</td>\n",
       "      <td>0.090490</td>\n",
       "      <td>0.180819</td>\n",
       "      <td>0.169705</td>\n",
       "      <td>0.060653</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.714838e-04</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.710332e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 8, 'p': 2}</td>\n",
       "      <td>0.219401</td>\n",
       "      <td>0.134825</td>\n",
       "      <td>0.150881</td>\n",
       "      <td>0.168369</td>\n",
       "      <td>0.036675</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.003001</td>\n",
       "      <td>8.151735e-04</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>4.705851e-04</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 24, 'p': 1}</td>\n",
       "      <td>0.163615</td>\n",
       "      <td>0.146488</td>\n",
       "      <td>0.189633</td>\n",
       "      <td>0.166579</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003001</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.714270e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 4, 'p': 1}</td>\n",
       "      <td>0.241942</td>\n",
       "      <td>0.085689</td>\n",
       "      <td>0.169289</td>\n",
       "      <td>0.165640</td>\n",
       "      <td>0.063842</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.002334</td>\n",
       "      <td>4.712580e-04</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 22, 'p': 1}</td>\n",
       "      <td>0.182240</td>\n",
       "      <td>0.139017</td>\n",
       "      <td>0.173719</td>\n",
       "      <td>0.164992</td>\n",
       "      <td>0.018694</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>8.170215e-04</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>4.724393e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 10, 'p': 2}</td>\n",
       "      <td>0.215909</td>\n",
       "      <td>0.143384</td>\n",
       "      <td>0.130931</td>\n",
       "      <td>0.163408</td>\n",
       "      <td>0.037470</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.003666</td>\n",
       "      <td>9.436399e-04</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>4.712580e-04</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 26, 'p': 1}</td>\n",
       "      <td>0.155951</td>\n",
       "      <td>0.149585</td>\n",
       "      <td>0.184582</td>\n",
       "      <td>0.163373</td>\n",
       "      <td>0.015221</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>6.836514e-07</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 25, 'p': 1}</td>\n",
       "      <td>0.162668</td>\n",
       "      <td>0.130579</td>\n",
       "      <td>0.185256</td>\n",
       "      <td>0.159501</td>\n",
       "      <td>0.022434</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002666</td>\n",
       "      <td>4.716514e-04</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.716514e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 15, 'p': 2}</td>\n",
       "      <td>0.207731</td>\n",
       "      <td>0.138811</td>\n",
       "      <td>0.112887</td>\n",
       "      <td>0.153143</td>\n",
       "      <td>0.040024</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.002668</td>\n",
       "      <td>4.697408e-04</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.969260e-06</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 34, 'p': 1}</td>\n",
       "      <td>0.148885</td>\n",
       "      <td>0.126118</td>\n",
       "      <td>0.181240</td>\n",
       "      <td>0.152081</td>\n",
       "      <td>0.022617</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.002334</td>\n",
       "      <td>4.712580e-04</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>3.893359e-07</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 27, 'p': 1}</td>\n",
       "      <td>0.149363</td>\n",
       "      <td>0.131589</td>\n",
       "      <td>0.171904</td>\n",
       "      <td>0.150952</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.003332</td>\n",
       "      <td>4.721591e-04</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>1.461091e-06</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 29, 'p': 1}</td>\n",
       "      <td>0.141388</td>\n",
       "      <td>0.123354</td>\n",
       "      <td>0.185112</td>\n",
       "      <td>0.149951</td>\n",
       "      <td>0.025929</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.002334</td>\n",
       "      <td>4.714838e-04</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>4.712023e-04</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 28, 'p': 1}</td>\n",
       "      <td>0.137017</td>\n",
       "      <td>0.131366</td>\n",
       "      <td>0.180083</td>\n",
       "      <td>0.149489</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "18       0.002667  4.717640e-04         0.002667    4.711459e-04   \n",
       "16       0.003000  8.778064e-07         0.002000    5.150430e-07   \n",
       "20       0.002667  4.710899e-04         0.002667    4.713704e-04   \n",
       "22       0.002333  4.711457e-04         0.002667    4.713171e-04   \n",
       "24       0.003001  8.485379e-07         0.002666    4.709228e-04   \n",
       "12       0.003004  6.072267e-06         0.002997    5.886359e-06   \n",
       "14       0.002667  4.717638e-04         0.002334    4.710899e-04   \n",
       "34       0.002334  4.709770e-04         0.002667    4.703588e-04   \n",
       "32       0.002333  4.718206e-04         0.002667    4.715952e-04   \n",
       "10       0.003665  4.722138e-04         0.003334    4.713714e-04   \n",
       "26       0.003666  9.428531e-04         0.003334    4.710902e-04   \n",
       "36       0.002667  4.699655e-04         0.003333    1.246895e-03   \n",
       "30       0.003333  1.247787e-03         0.003000    4.495664e-07   \n",
       "28       0.003000  3.371748e-07         0.002667    4.716514e-04   \n",
       "44       0.002667  4.713142e-04         0.003001    1.593426e-06   \n",
       "40       0.003335  4.701373e-04         0.003333    4.723286e-04   \n",
       "38       0.003000  1.083865e-06         0.003000    5.150430e-07   \n",
       "8        0.002666  4.723258e-04         0.002667    4.709770e-04   \n",
       "15       0.002667  4.714838e-04         0.002667    4.710332e-04   \n",
       "46       0.003001  8.151735e-04         0.002666    4.705851e-04   \n",
       "6        0.003001  1.123916e-07         0.002667    4.714270e-04   \n",
       "42       0.002334  4.712580e-04         0.003000    1.946680e-07   \n",
       "19       0.003000  8.170215e-04         0.002334    4.724393e-04   \n",
       "50       0.003666  9.436399e-04         0.003333    4.712580e-04   \n",
       "48       0.003000  6.836514e-07         0.003001    4.052337e-07   \n",
       "29       0.002666  4.716514e-04         0.002667    4.716514e-04   \n",
       "66       0.002668  4.697408e-04         0.003000    1.969260e-06   \n",
       "52       0.002334  4.712580e-04         0.003000    3.893359e-07   \n",
       "56       0.003332  4.721591e-04         0.003001    1.461091e-06   \n",
       "54       0.002334  4.714838e-04         0.002666    4.712023e-04   \n",
       "\n",
       "   param_n_neighbors param_p                       params  split0_test_score  \\\n",
       "18                10       1  {'n_neighbors': 10, 'p': 1}           0.229380   \n",
       "16                 9       1   {'n_neighbors': 9, 'p': 1}           0.244063   \n",
       "20                11       1  {'n_neighbors': 11, 'p': 1}           0.207859   \n",
       "22                12       1  {'n_neighbors': 12, 'p': 1}           0.218679   \n",
       "24                13       1  {'n_neighbors': 13, 'p': 1}           0.212236   \n",
       "12                 7       1   {'n_neighbors': 7, 'p': 1}           0.260543   \n",
       "14                 8       1   {'n_neighbors': 8, 'p': 1}           0.242088   \n",
       "34                18       1  {'n_neighbors': 18, 'p': 1}           0.208390   \n",
       "32                17       1  {'n_neighbors': 17, 'p': 1}           0.213273   \n",
       "10                 6       1   {'n_neighbors': 6, 'p': 1}           0.257719   \n",
       "26                14       1  {'n_neighbors': 14, 'p': 1}           0.227398   \n",
       "36                19       1  {'n_neighbors': 19, 'p': 1}           0.196063   \n",
       "30                16       1  {'n_neighbors': 16, 'p': 1}           0.210112   \n",
       "28                15       1  {'n_neighbors': 15, 'p': 1}           0.224716   \n",
       "44                23       1  {'n_neighbors': 23, 'p': 1}           0.177023   \n",
       "40                21       1  {'n_neighbors': 21, 'p': 1}           0.183026   \n",
       "38                20       1  {'n_neighbors': 20, 'p': 1}           0.192427   \n",
       "8                  5       1   {'n_neighbors': 5, 'p': 1}           0.237805   \n",
       "15                 8       2   {'n_neighbors': 8, 'p': 2}           0.219401   \n",
       "46                24       1  {'n_neighbors': 24, 'p': 1}           0.163615   \n",
       "6                  4       1   {'n_neighbors': 4, 'p': 1}           0.241942   \n",
       "42                22       1  {'n_neighbors': 22, 'p': 1}           0.182240   \n",
       "19                10       2  {'n_neighbors': 10, 'p': 2}           0.215909   \n",
       "50                26       1  {'n_neighbors': 26, 'p': 1}           0.155951   \n",
       "48                25       1  {'n_neighbors': 25, 'p': 1}           0.162668   \n",
       "29                15       2  {'n_neighbors': 15, 'p': 2}           0.207731   \n",
       "66                34       1  {'n_neighbors': 34, 'p': 1}           0.148885   \n",
       "52                27       1  {'n_neighbors': 27, 'p': 1}           0.149363   \n",
       "56                29       1  {'n_neighbors': 29, 'p': 1}           0.141388   \n",
       "54                28       1  {'n_neighbors': 28, 'p': 1}           0.137017   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "18           0.246877           0.208324         0.228193        0.015761   \n",
       "16           0.205266           0.203059         0.217463        0.018831   \n",
       "20           0.220736           0.190853         0.206483        0.012238   \n",
       "22           0.181953           0.204883         0.201838        0.015147   \n",
       "24           0.182456           0.208280         0.200991        0.013205   \n",
       "12           0.164098           0.174650         0.199764        0.043193   \n",
       "14           0.179581           0.168821         0.196830        0.032302   \n",
       "34           0.150668           0.220634         0.193231        0.030509   \n",
       "32           0.151596           0.209493         0.191454        0.028226   \n",
       "10           0.129691           0.175037         0.187483        0.053003   \n",
       "26           0.133082           0.196499         0.185660        0.039260   \n",
       "36           0.155385           0.204649         0.185365        0.021487   \n",
       "30           0.142128           0.203293         0.185178        0.030568   \n",
       "28           0.146465           0.179379         0.183520        0.032080   \n",
       "44           0.158751           0.185984         0.173920        0.011333   \n",
       "40           0.162003           0.172124         0.172384        0.008585   \n",
       "38           0.141649           0.181823         0.171966        0.021870   \n",
       "8            0.090490           0.180819         0.169705        0.060653   \n",
       "15           0.134825           0.150881         0.168369        0.036675   \n",
       "46           0.146488           0.189633         0.166579        0.017738   \n",
       "6            0.085689           0.169289         0.165640        0.063842   \n",
       "42           0.139017           0.173719         0.164992        0.018694   \n",
       "19           0.143384           0.130931         0.163408        0.037470   \n",
       "50           0.149585           0.184582         0.163373        0.015221   \n",
       "48           0.130579           0.185256         0.159501        0.022434   \n",
       "29           0.138811           0.112887         0.153143        0.040024   \n",
       "66           0.126118           0.181240         0.152081        0.022617   \n",
       "52           0.131589           0.171904         0.150952        0.016497   \n",
       "56           0.123354           0.185112         0.149951        0.025929   \n",
       "54           0.131366           0.180083         0.149489        0.021756   \n",
       "\n",
       "    rank_test_score  \n",
       "18                1  \n",
       "16                2  \n",
       "20                3  \n",
       "22                4  \n",
       "24                5  \n",
       "12                6  \n",
       "14                7  \n",
       "34                8  \n",
       "32                9  \n",
       "10               10  \n",
       "26               11  \n",
       "36               12  \n",
       "30               13  \n",
       "28               14  \n",
       "44               15  \n",
       "40               16  \n",
       "38               17  \n",
       "8                18  \n",
       "15               19  \n",
       "46               20  \n",
       "6                21  \n",
       "42               22  \n",
       "19               23  \n",
       "50               24  \n",
       "48               25  \n",
       "29               26  \n",
       "66               27  \n",
       "52               28  \n",
       "56               29  \n",
       "54               30  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(30)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39181242496082125\n",
      "0.17253887513811672\n",
      "Training RMSE:  28.245223628204982\n",
      "Test RMSE:  41.54089234036877\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsRegressor(n_neighbors=10, p=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train,y_train_prediction)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,y_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4460925944234674\n",
      "0.22309733479197058\n",
      "Training RMSE:  26.955341083157336\n",
      "Test RMSE:  40.25180197326084\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsRegressor(n_neighbors=7, p=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train,y_train_prediction)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,y_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4510330360444692\n",
      "0.3133711503417126\n",
      "Training RMSE:  26.83486104756014\n",
      "Test RMSE:  37.84103838488727\n"
     ]
    }
   ],
   "source": [
    "#BEST\n",
    "knn=KNeighborsRegressor(n_neighbors=5, p=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train,y_train_prediction)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,y_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37363918074297675\n",
      "0.17388123067711403\n",
      "Training RMSE:  28.664115000944566\n",
      "Test RMSE:  41.507183638554075\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsRegressor(n_neighbors=8, p=2)\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"Training RMSE: \", np.sqrt(metrics.mean_squared_error(y_train,y_train_prediction)))\n",
    "print(\"Test RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,y_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43853820598006643\n",
      "0.20930232558139536\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train, yCat_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, yCat_train))\n",
    "print(knn.score(X_test, yCat_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30570957095709567"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid= {'n_neighbors': np.arange(1,40),\n",
    "            'p':[1,2]}\n",
    "grid_search= GridSearchCV(knn, param_grid, cv=3)\n",
    "grid_search.fit(X_train, yCat_train)\n",
    "print(grid_search.best_estimator_)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.715966e-04</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>4.702466e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 31, 'p': 2}</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.305710</td>\n",
       "      <td>0.039021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.002661</td>\n",
       "      <td>4.672009e-04</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>1.246746e-03</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 30, 'p': 2}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.302409</td>\n",
       "      <td>0.040830</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>7.867412e-07</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>4.709770e-04</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 34, 'p': 1}</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.302343</td>\n",
       "      <td>0.020755</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>4.710894e-04</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>9.429093e-04</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 32, 'p': 1}</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.302310</td>\n",
       "      <td>0.016654</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>8.167294e-04</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>4.710332e-04</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 32, 'p': 2}</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.299010</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>8.178001e-04</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>8.169242e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 31, 'p': 1}</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.298977</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.003667</td>\n",
       "      <td>1.247724e-03</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>2.160973e-03</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 36, 'p': 1}</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.295710</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>6.743496e-07</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>8.104673e-07</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 35, 'p': 1}</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.295710</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.140650e-06</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>3.371748e-07</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 37, 'p': 1}</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.295710</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.003668</td>\n",
       "      <td>9.422915e-04</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>1.247618e-03</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 33, 'p': 1}</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.295677</td>\n",
       "      <td>0.012285</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.004334</td>\n",
       "      <td>9.419553e-04</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>1.247299e-03</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 29, 'p': 2}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.292409</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.003009</td>\n",
       "      <td>8.719589e-06</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>4.616560e-04</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 28, 'p': 2}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.292409</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.714876e-04</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>4.739004e-04</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 33, 'p': 2}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.292409</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.003001</td>\n",
       "      <td>9.989584e-07</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>4.710916e-04</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 29, 'p': 1}</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.292343</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>4.708086e-04</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 27, 'p': 2}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.289076</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.003001</td>\n",
       "      <td>7.370010e-07</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.106929e-06</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 30, 'p': 1}</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.289010</td>\n",
       "      <td>0.013497</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.002666</td>\n",
       "      <td>4.712030e-04</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>4.717077e-04</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 28, 'p': 1}</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.289010</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.003335</td>\n",
       "      <td>4.707530e-04</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>4.706398e-04</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 19, 'p': 1}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.285743</td>\n",
       "      <td>0.025224</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>4.715412e-04</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>4.704151e-04</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 26, 'p': 2}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.285743</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>5.947204e-07</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>9.199649e-07</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 18, 'p': 1}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.285743</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.003668</td>\n",
       "      <td>4.712590e-04</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>1.700657e-03</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 34, 'p': 2}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.285743</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.003332</td>\n",
       "      <td>4.713723e-04</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>1.247235e-03</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 38, 'p': 1}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.285743</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.717075e-04</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>4.899036e-07</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 36, 'p': 2}</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.285710</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>4.727194e-04</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>4.698536e-04</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 20, 'p': 2}</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.285710</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>3.893359e-07</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 25, 'p': 1}</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.285677</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.717082e-04</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>4.704151e-04</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 35, 'p': 2}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.282409</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>5.150430e-07</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>5.947204e-07</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 21, 'p': 1}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.282409</td>\n",
       "      <td>0.020739</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.002999</td>\n",
       "      <td>9.199649e-07</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>4.723819e-04</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 26, 'p': 1}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.282409</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.716516e-04</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 39, 'p': 1}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.282409</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>5.947204e-07</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>4.712580e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 10, 'p': 1}</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.282409</td>\n",
       "      <td>0.020739</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "61       0.003667  4.715966e-04         0.007333    4.702466e-04   \n",
       "59       0.002661  4.672009e-04         0.007334    1.246746e-03   \n",
       "66       0.003000  7.867412e-07         0.006334    4.709770e-04   \n",
       "62       0.003333  4.710894e-04         0.007667    9.429093e-04   \n",
       "63       0.003000  8.167294e-04         0.007334    4.710332e-04   \n",
       "60       0.004000  8.178001e-04         0.007000    8.169242e-04   \n",
       "70       0.003667  1.247724e-03         0.008000    2.160973e-03   \n",
       "68       0.003000  6.743496e-07         0.007001    8.104673e-07   \n",
       "72       0.003000  1.140650e-06         0.006001    3.371748e-07   \n",
       "64       0.003668  9.422915e-04         0.007333    1.247618e-03   \n",
       "57       0.004334  9.419553e-04         0.008666    1.247299e-03   \n",
       "55       0.003009  8.719589e-06         0.006325    4.616560e-04   \n",
       "65       0.002667  4.714876e-04         0.006667    4.739004e-04   \n",
       "56       0.003001  9.989584e-07         0.006667    4.710916e-04   \n",
       "53       0.003334  4.713704e-04         0.006335    4.708086e-04   \n",
       "58       0.003001  7.370010e-07         0.006000    1.106929e-06   \n",
       "54       0.002666  4.712030e-04         0.006334    4.717077e-04   \n",
       "36       0.003335  4.707530e-04         0.006333    4.706398e-04   \n",
       "51       0.003333  4.715412e-04         0.006668    4.704151e-04   \n",
       "34       0.003000  5.947204e-07         0.006001    9.199649e-07   \n",
       "67       0.003668  4.712590e-04         0.007666    1.700657e-03   \n",
       "74       0.003332  4.713723e-04         0.008334    1.247235e-03   \n",
       "71       0.003334  4.717075e-04         0.006001    4.899036e-07   \n",
       "39       0.003333  4.727194e-04         0.006668    4.698536e-04   \n",
       "48       0.003000  1.123916e-07         0.006001    3.893359e-07   \n",
       "69       0.003334  4.717082e-04         0.006334    4.704151e-04   \n",
       "40       0.003000  5.150430e-07         0.007000    5.947204e-07   \n",
       "50       0.002999  9.199649e-07         0.006335    4.723819e-04   \n",
       "76       0.002667  4.716516e-04         0.006334    4.714266e-04   \n",
       "18       0.003000  5.947204e-07         0.006668    4.712580e-04   \n",
       "\n",
       "   param_n_neighbors param_p                       params  split0_test_score  \\\n",
       "61                31       2  {'n_neighbors': 31, 'p': 2}           0.287129   \n",
       "59                30       2  {'n_neighbors': 30, 'p': 2}           0.277228   \n",
       "66                34       1  {'n_neighbors': 34, 'p': 1}           0.297030   \n",
       "62                32       1  {'n_neighbors': 32, 'p': 1}           0.306931   \n",
       "63                32       2  {'n_neighbors': 32, 'p': 2}           0.297030   \n",
       "60                31       1  {'n_neighbors': 31, 'p': 1}           0.306931   \n",
       "70                36       1  {'n_neighbors': 36, 'p': 1}           0.287129   \n",
       "68                35       1  {'n_neighbors': 35, 'p': 1}           0.287129   \n",
       "72                37       1  {'n_neighbors': 37, 'p': 1}           0.287129   \n",
       "64                33       1  {'n_neighbors': 33, 'p': 1}           0.297030   \n",
       "57                29       2  {'n_neighbors': 29, 'p': 2}           0.277228   \n",
       "55                28       2  {'n_neighbors': 28, 'p': 2}           0.277228   \n",
       "65                33       2  {'n_neighbors': 33, 'p': 2}           0.277228   \n",
       "56                29       1  {'n_neighbors': 29, 'p': 1}           0.297030   \n",
       "53                27       2  {'n_neighbors': 27, 'p': 2}           0.277228   \n",
       "58                30       1  {'n_neighbors': 30, 'p': 1}           0.297030   \n",
       "54                28       1  {'n_neighbors': 28, 'p': 1}           0.297030   \n",
       "36                19       1  {'n_neighbors': 19, 'p': 1}           0.277228   \n",
       "51                26       2  {'n_neighbors': 26, 'p': 2}           0.277228   \n",
       "34                18       1  {'n_neighbors': 18, 'p': 1}           0.277228   \n",
       "67                34       2  {'n_neighbors': 34, 'p': 2}           0.277228   \n",
       "74                38       1  {'n_neighbors': 38, 'p': 1}           0.277228   \n",
       "71                36       2  {'n_neighbors': 36, 'p': 2}           0.287129   \n",
       "39                20       2  {'n_neighbors': 20, 'p': 2}           0.287129   \n",
       "48                25       1  {'n_neighbors': 25, 'p': 1}           0.297030   \n",
       "69                35       2  {'n_neighbors': 35, 'p': 2}           0.277228   \n",
       "40                21       1  {'n_neighbors': 21, 'p': 1}           0.277228   \n",
       "50                26       1  {'n_neighbors': 26, 'p': 1}           0.277228   \n",
       "76                39       1  {'n_neighbors': 39, 'p': 1}           0.277228   \n",
       "18                10       1  {'n_neighbors': 10, 'p': 1}           0.277228   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "61               0.36               0.27         0.305710        0.039021   \n",
       "59               0.36               0.27         0.302409        0.040830   \n",
       "66               0.33               0.28         0.302343        0.020755   \n",
       "62               0.32               0.28         0.302310        0.016654   \n",
       "63               0.33               0.27         0.299010        0.024535   \n",
       "60               0.32               0.27         0.298977        0.021173   \n",
       "70               0.32               0.28         0.295710        0.017421   \n",
       "68               0.32               0.28         0.295710        0.017421   \n",
       "72               0.32               0.28         0.295710        0.017421   \n",
       "64               0.31               0.28         0.295677        0.012285   \n",
       "57               0.33               0.27         0.292409        0.026744   \n",
       "55               0.33               0.27         0.292409        0.026744   \n",
       "65               0.33               0.27         0.292409        0.026744   \n",
       "56               0.30               0.28         0.292343        0.008812   \n",
       "53               0.32               0.27         0.289076        0.022065   \n",
       "58               0.30               0.27         0.289010        0.013497   \n",
       "54               0.29               0.28         0.289010        0.006988   \n",
       "36               0.32               0.26         0.285743        0.025224   \n",
       "51               0.31               0.27         0.285743        0.017405   \n",
       "34               0.31               0.27         0.285743        0.017405   \n",
       "67               0.31               0.27         0.285743        0.017405   \n",
       "74               0.30               0.28         0.285743        0.010145   \n",
       "71               0.30               0.27         0.285710        0.012288   \n",
       "39               0.31               0.26         0.285710        0.020437   \n",
       "48               0.29               0.27         0.285677        0.011450   \n",
       "69               0.30               0.27         0.282409        0.012784   \n",
       "40               0.31               0.26         0.282409        0.020739   \n",
       "50               0.30               0.27         0.282409        0.012784   \n",
       "76               0.30               0.27         0.282409        0.012784   \n",
       "18               0.31               0.26         0.282409        0.020739   \n",
       "\n",
       "    rank_test_score  \n",
       "61                1  \n",
       "59                2  \n",
       "66                3  \n",
       "62                4  \n",
       "63                5  \n",
       "60                6  \n",
       "70                7  \n",
       "68                7  \n",
       "72                7  \n",
       "64               10  \n",
       "57               11  \n",
       "55               11  \n",
       "65               11  \n",
       "56               14  \n",
       "53               15  \n",
       "58               16  \n",
       "54               16  \n",
       "36               18  \n",
       "51               18  \n",
       "34               18  \n",
       "67               18  \n",
       "74               18  \n",
       "71               23  \n",
       "39               23  \n",
       "48               25  \n",
       "69               26  \n",
       "40               26  \n",
       "50               26  \n",
       "76               26  \n",
       "18               26  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by=['rank_test_score'], inplace=True)\n",
    "results.head(30)\n",
    "#order by rank test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3089700996677741\n",
      "0.20930232558139536\n"
     ]
    }
   ],
   "source": [
    "#BEST\n",
    "knn=KNeighborsClassifier(n_neighbors=31, p=2)\n",
    "knn.fit(X_train, yCat_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, yCat_train))\n",
    "print(knn.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30564784053156147\n",
      "0.20930232558139536\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=34, p=2)\n",
    "knn.fit(X_train, yCat_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, yCat_train))\n",
    "print(knn.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31561461794019935\n",
      "0.20930232558139536\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=29, p=2)\n",
    "knn.fit(X_train, yCat_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, yCat_train))\n",
    "print(knn.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39867109634551495\n",
      "0.1937984496124031\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=10, p=1)\n",
    "knn.fit(X_train, yCat_train)\n",
    "y_train_prediction=knn.predict(X_train)\n",
    "y_prediction=knn.predict(X_test)\n",
    "print(knn.score(X_train, yCat_train))\n",
    "print(knn.score(X_test, yCat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
